<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0033)http://www.convnet.me/papers.html -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Archtectures</title>
<meta name="viewport" content="width=1200, initial-scale=1, maximum-scale=1, user-scalable=no">
</head>
<body style="width:1200; margin:0 auto;">

    <table style="border-width: 0px; width: 1200px;" border="1">
        <tr>
          <td style="border-style: none; border-width: medium;"
            width="19" valign="top"> &nbsp; </td>
          <td style="border-style: none; border-width: medium;"
            bgcolor="#999999" width="14" valign="top"> &nbsp; </td>
          <td style="border-style: none; border-width: medium;"
            width="550" valign="top">
            <p style="margin-left: 10px; line-height: 150%; margin-top:
              8px; margin-bottom: 8px;"> <strong><i><font face="Arial">
              [AlexNet] ImageNet Classification with Deep Convolutional Neural Networks <br>
                </font></i> </strong><font face="Arial" size="2">
              <a href="http://papers.nips.cc/paper/4824-imagenet-classification-with-deep-">NIPS-Proc</a>&nbsp;&nbsp;
              <a href="http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf">slides</a>
              <a href="https://github.com/dnouri/cuda-convnet">code</a>
            </p>
          </td>
          <td style="border-style: none; border-width: medium;"
            bgcolor="#999999" width="14" valign="top"> &nbsp; </td>
          <td style="border-style: none; border-width: medium;"
            width="550" valign="top">
            <p style="margin-left: 10px; line-height: 150%; margin-top:
              8px; margin-bottom: 8px;"> 
              <img src="AlexNet.jpg" width="550">
            </p>
          </td>
        </tr>
      
      
      
      
    </table>

<h2 id="network-in-network">Network In Network</h2>

<p><strong>Network In Network</strong></p>

<ul>
  <li>intro: ICLR 2014</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1312.4400">http://arxiv.org/abs/1312.4400</a></li>
  <li>gitxiv: <a href="http://gitxiv.com/posts/PA98qGuMhsijsJzgX/network-in-network-nin">http://gitxiv.com/posts/PA98qGuMhsijsJzgX/network-in-network-nin</a></li>
  <li>code(Caffe, official): <a href="https://gist.github.com/mavenlin/d802a5849de39225bcc6">https://gist.github.com/mavenlin/d802a5849de39225bcc6</a></li>
</ul>

<p><strong>Batch-normalized Maxout Network in Network</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.02583">http://arxiv.org/abs/1511.02583</a></li>
</ul>

<h2 id="googlenet-inception-v1">GoogLeNet (Inception V1)</h2>

<p><strong>Going Deeper with Convolutions</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1409.4842">http://arxiv.org/abs/1409.4842</a></li>
  <li>github: <a href="https://github.com/google/inception">https://github.com/google/inception</a></li>
  <li>github: <a href="https://github.com/soumith/inception.torch">https://github.com/soumith/inception.torch</a></li>
</ul>

<p><strong>Building a deeper understanding of images</strong></p>

<ul>
  <li>blog: <a href="http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html">http://googleresearch.blogspot.jp/2014/09/building-deeper-understanding-of-images.html</a></li>
</ul>

<h2 id="vggnet">VGGNet</h2>

<p><strong>Very Deep Convolutional Networks for Large-Scale Image Recognition</strong></p>

<ul>
  <li>homepage: <a href="http://www.robots.ox.ac.uk/~vgg/research/very_deep/">http://www.robots.ox.ac.uk/~vgg/research/very_deep/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1409.1556">http://arxiv.org/abs/1409.1556</a></li>
  <li>slides: <a href="http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx">http://llcao.net/cu-deeplearning15/presentation/cc3580_Simonyan.pptx</a></li>
  <li>slides: <a href="http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf">http://www.robots.ox.ac.uk/~karen/pdf/ILSVRC_2014.pdf</a></li>
  <li>slides: <a href="http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf">http://deeplearning.cs.cmu.edu/slides.2015/25.simonyan.pdf</a></li>
  <li>github(official, deprecated Caffe API): <a href="https://gist.github.com/ksimonyan/211839e770f7b538e2d8">https://gist.github.com/ksimonyan/211839e770f7b538e2d8</a></li>
  <li>github: <a href="https://github.com/ruimashita/caffe-train">https://github.com/ruimashita/caffe-train</a></li>
</ul>

<p><strong>Tensorflow VGG16 and VGG19</strong></p>

<ul>
  <li>github: <a href="https://github.com/machrisaa/tensorflow-vgg">https://github.com/machrisaa/tensorflow-vgg</a></li>
</ul>

<h2 id="inception-v2">Inception-V2</h2>

<p><strong>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</strong></p>

<ul>
  <li>intro: ImageNet top-5 error: 4.82%</li>
  <li>keywords: internal covariate shift problem</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1502.03167">http://arxiv.org/abs/1502.03167</a></li>
  <li>blog: <a href="https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/">https://standardfrancis.wordpress.com/2015/04/16/batch-normalization/</a></li>
  <li>notes: <a href="http://blog.csdn.net/happynear/article/details/44238541">http://blog.csdn.net/happynear/article/details/44238541</a></li>
  <li>github: <a href="https://github.com/lim0606/caffe-googlenet-bn">https://github.com/lim0606/caffe-googlenet-bn</a></li>
</ul>

<p><strong>ImageNet pre-trained models with batch normalization</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01452">https://arxiv.org/abs/1612.01452</a></li>
  <li>project page: <a href="http://www.inf-cv.uni-jena.de/Research/CNN+Models.html">http://www.inf-cv.uni-jena.de/Research/CNN+Models.html</a></li>
  <li>github: <a href="https://github.com/cvjena/cnn-models">https://github.com/cvjena/cnn-models</a></li>
</ul>

<h2 id="inception-v3">Inception-V3</h2>

<p>Inception-V3 = Inception-V2 + BN-auxiliary (fully connected layer of the auxiliary classifier is also batch-normalized, 
not just the convolutions)</p>

<p><strong>Rethinking the Inception Architecture for Computer Vision</strong></p>

<ul>
  <li>intro: “21.2% top-1 and 5.6% top-5 error for single frame evaluation using a network; 
3.5% top-5 error and 17.3% top-1 error With an ensemble of 4 models and multi-crop evaluation.”</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.00567">http://arxiv.org/abs/1512.00567</a></li>
  <li>github: <a href="https://github.com/Moodstocks/inception-v3.torch">https://github.com/Moodstocks/inception-v3.torch</a></li>
</ul>

<p><strong>Inception in TensorFlow</strong></p>

<ul>
  <li>intro: demonstrate how to train the Inception v3 architecture</li>
  <li>github: <a href="https://github.com/tensorflow/models/tree/master/inception">https://github.com/tensorflow/models/tree/master/inception</a></li>
</ul>

<p><strong>Train your own image classifier with Inception in TensorFlow</strong></p>

<ul>
  <li>intro: Inception-v3</li>
  <li>blog: <a href="https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html">https://research.googleblog.com/2016/03/train-your-own-image-classifier-with.html</a></li>
</ul>

<p><strong>Notes on the TensorFlow Implementation of Inception v3</strong></p>

<p><a href="https://pseudoprofound.wordpress.com/2016/08/28/notes-on-the-tensorflow-implementation-of-inception-v3/">https://pseudoprofound.wordpress.com/2016/08/28/notes-on-the-tensorflow-implementation-of-inception-v3/</a></p>

<p><strong>Training an InceptionV3-based image classifier with your own dataset</strong></p>

<ul>
  <li>github: <a href="https://github.com/danielvarga/keras-finetuning">https://github.com/danielvarga/keras-finetuning</a></li>
</ul>

<p><strong>Inception-BN full for Caffe: Inception-BN ImageNet (21K classes) model for Caffe</strong></p>

<ul>
  <li>github: <a href="https://github.com/pertusa/InceptionBN-21K-for-Caffe">https://github.com/pertusa/InceptionBN-21K-for-Caffe</a></li>
</ul>

<h2 id="resnet">ResNet</h2>

<p><strong>Deep Residual Learning for Image Recognition</strong></p>

<ul>
  <li>intro: CVPR 2016 Best Paper Award</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.03385">http://arxiv.org/abs/1512.03385</a></li>
  <li>slides: <a href="http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf">http://research.microsoft.com/en-us/um/people/kahe/ilsvrc15/ilsvrc2015_deep_residual_learning_kaiminghe.pdf</a></li>
  <li>gitxiv: <a href="http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition">http://gitxiv.com/posts/LgPRdTY3cwPBiMKbm/deep-residual-learning-for-image-recognition</a></li>
  <li>github: <a href="https://github.com/KaimingHe/deep-residual-networks">https://github.com/KaimingHe/deep-residual-networks</a></li>
  <li>github: <a href="https://github.com/ry/tensorflow-resnet">https://github.com/ry/tensorflow-resnet</a></li>
</ul>

<p><strong>Third-party re-implementations</strong></p>

<p><a href="https://github.com/KaimingHe/deep-residual-networks#third-party-re-implementations">https://github.com/KaimingHe/deep-residual-networks#third-party-re-implementations</a></p>

<p><strong>Training and investigating Residual Nets</strong></p>

<ul>
  <li>intro: Facebook AI Research</li>
  <li>blog: <a href="http://torch.ch/blog/2016/02/04/resnets.html">http://torch.ch/blog/2016/02/04/resnets.html</a></li>
  <li>github: <a href="https://github.com/facebook/fb.resnet.torch">https://github.com/facebook/fb.resnet.torch</a></li>
</ul>

<p><strong>resnet.torch: an updated version of fb.resnet.torch with many changes.</strong></p>

<ul>
  <li>github: <a href="https://github.com/erogol/resnet.torch">https://github.com/erogol/resnet.torch</a></li>
</ul>

<p><strong>Highway Networks and Deep Residual Networks</strong></p>

<ul>
  <li>blog: <a href="http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html">http://yanran.li/peppypapers/2016/01/10/highway-networks-and-deep-residual-networks.html</a></li>
</ul>

<p><strong>Interpretating Deep Residual Learning Blocks as Locally Recurrent Connections</strong></p>

<ul>
  <li>blog: <a href="https://matrixmashing.wordpress.com/2016/01/29/interpretating-deep-residual-learning-blocks-as-locally-recurrent-connections/">https://matrixmashing.wordpress.com/2016/01/29/interpretating-deep-residual-learning-blocks-as-locally-recurrent-connections/</a></li>
</ul>

<p><strong>Lab41 Reading Group: Deep Residual Learning for Image Recognition</strong></p>

<ul>
  <li>blog: <a href="https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f">https://gab41.lab41.org/lab41-reading-group-deep-residual-learning-for-image-recognition-ffeb94745a1f</a></li>
</ul>

<p><strong>50-layer ResNet, trained on ImageNet, classifying webcam</strong></p>

<ul>
  <li>homepage: <a href="https://ml4a.github.io/demos/keras.js/">https://ml4a.github.io/demos/keras.js/</a></li>
</ul>

<p><strong>Reproduced ResNet on CIFAR-10 and CIFAR-100 dataset.</strong></p>

<ul>
  <li>github: <a href="https://github.com/tensorflow/models/tree/master/resnet">https://github.com/tensorflow/models/tree/master/resnet</a></li>
</ul>

<h2 id="resnet-v2">ResNet-V2</h2>

<p><strong>Identity Mappings in Deep Residual Networks</strong></p>

<ul>
  <li>intro: ECCV 2016. ResNet-v2</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.05027">http://arxiv.org/abs/1603.05027</a></li>
  <li>github: <a href="https://github.com/KaimingHe/resnet-1k-layers">https://github.com/KaimingHe/resnet-1k-layers</a></li>
  <li>github: <a href="https://github.com/tornadomeet/ResNet">https://github.com/tornadomeet/ResNet</a></li>
</ul>

<p><strong>Deep Residual Networks for Image Classification with Python + NumPy</strong></p>

<p><img src="https://dnlcrl.github.io/assets/thesis-post/Diagramma.png" height="300" alt="" /></p>

<ul>
  <li>blog: <a href="https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html">https://dnlcrl.github.io/projects/2016/06/22/Deep-Residual-Networks-for-Image-Classification-with-Python+NumPy.html</a></li>
</ul>

<h2 id="inception-v4--inception-resnet-v2">Inception-V4 / Inception-ResNet-V2</h2>

<p><strong>Inception-V4, Inception-Resnet And The Impact Of Residual Connections On Learning</strong></p>

<ul>
  <li>intro: Workshop track - ICLR 2016. 3.08 % top-5 error on ImageNet CLS</li>
  <li>intro: “achieve 3.08% top-5 error on the test set of the ImageNet classification (CLS) challenge”</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.07261">http://arxiv.org/abs/1602.07261</a></li>
  <li>github(Keras): <a href="https://github.com/kentsommer/keras-inceptionV4">https://github.com/kentsommer/keras-inceptionV4</a></li>
</ul>

<p><strong>The inception-resnet-v2 models trained from scratch via torch</strong></p>

<ul>
  <li>github: <a href="https://github.com/lim0606/torch-inception-resnet-v2">https://github.com/lim0606/torch-inception-resnet-v2</a></li>
</ul>

<p><strong>Inception v4 in Keras</strong></p>

<ul>
  <li>intro: Inception-v4, Inception - Resnet-v1 and v2</li>
  <li>github: <a href="https://github.com/titu1994/Inception-v4">https://github.com/titu1994/Inception-v4</a></li>
</ul>

<h2 id="resnext">ResNeXt</h2>

<p><strong>Aggregated Residual Transformations for Deep Neural Networks</strong></p>

<ul>
  <li>intro: CVPR 2017. UC San Diego &amp; Facebook AI Research</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.05431">https://arxiv.org/abs/1611.05431</a></li>
  <li>github(Torch): <a href="https://github.com/facebookresearch/ResNeXt">https://github.com/facebookresearch/ResNeXt</a></li>
  <li>github: <a href="https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol/resnext.py">https://github.com/dmlc/mxnet/blob/master/example/image-classification/symbol/resnext.py</a></li>
  <li>dataset: <a href="http://data.dmlc.ml/models/imagenet/resnext/">http://data.dmlc.ml/models/imagenet/resnext/</a></li>
  <li>reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/">https://www.reddit.com/r/MachineLearning/comments/5haml9/p_implementation_of_aggregated_residual/</a></li>
</ul>

<h2 id="residual-networks-variants">Residual Networks Variants</h2>

<p><strong>Resnet in Resnet: Generalizing Residual Architectures</strong></p>

<ul>
  <li>paper: <a href="http://beta.openreview.net/forum?id=lx9l4r36gU2OVPy8Cv9g">http://beta.openreview.net/forum?id=lx9l4r36gU2OVPy8Cv9g</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.08029">http://arxiv.org/abs/1603.08029</a></li>
</ul>

<p><strong>Residual Networks are Exponential Ensembles of Relatively Shallow Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.06431">http://arxiv.org/abs/1605.06431</a></li>
</ul>

<p><strong>Wide Residual Networks</strong></p>

<ul>
  <li>intro: BMVC 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.07146">http://arxiv.org/abs/1605.07146</a></li>
  <li>github: <a href="https://github.com/szagoruyko/wide-residual-networks">https://github.com/szagoruyko/wide-residual-networks</a></li>
  <li>github: <a href="https://github.com/asmith26/wide_resnets_keras">https://github.com/asmith26/wide_resnets_keras</a></li>
  <li>github: <a href="https://github.com/ritchieng/wideresnet-tensorlayer">https://github.com/ritchieng/wideresnet-tensorlayer</a></li>
  <li>github: <a href="https://github.com/xternalz/WideResNet-pytorch">https://github.com/xternalz/WideResNet-pytorch</a></li>
  <li>github(Torch): <a href="https://github.com/meliketoy/wide-residual-network">https://github.com/meliketoy/wide-residual-network</a></li>
</ul>

<p><strong>Residual Networks of Residual Networks: Multilevel Residual Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.02908">http://arxiv.org/abs/1608.02908</a></li>
</ul>

<p><strong>Multi-Residual Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.05672">http://arxiv.org/abs/1609.05672</a></li>
  <li>github: <a href="https://github.com/masoudabd/multi-resnet">https://github.com/masoudabd/multi-resnet</a></li>
</ul>

<p><strong>Deep Pyramidal Residual Networks</strong></p>

<ul>
  <li>intro: PyramidNet</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.02915">https://arxiv.org/abs/1610.02915</a></li>
  <li>github: <a href="https://github.com/jhkim89/PyramidNet">https://github.com/jhkim89/PyramidNet</a></li>
</ul>

<p><strong>Learning Identity Mappings with Residual Gates</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.01260">https://arxiv.org/abs/1611.01260</a></li>
</ul>

<p><strong>Wider or Deeper: Revisiting the ResNet Model for Visual Recognition</strong></p>

<ul>
  <li>intro: image classification, semantic image segmentation</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.10080">https://arxiv.org/abs/1611.10080</a></li>
  <li>github: <a href="https://github.com/itijyou/ademxapp">https://github.com/itijyou/ademxapp</a></li>
</ul>

<p><strong>Deep Pyramidal Residual Networks with Separated Stochastic Depth</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01230">https://arxiv.org/abs/1612.01230</a></li>
</ul>

<p><strong>Spatially Adaptive Computation Time for Residual Networks</strong></p>

<ul>
  <li>intro: Higher School of Economics &amp; Google &amp; CMU</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.02297">https://arxiv.org/abs/1612.02297</a></li>
</ul>

<p><strong>ShaResNet: reducing residual network parameter number by sharing weights</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.08782">https://arxiv.org/abs/1702.08782</a></li>
  <li>github: <a href="https://github.com/aboulch/sharesnet">https://github.com/aboulch/sharesnet</a></li>
</ul>

<p><strong>Sharing Residual Units Through Collective Tensor Factorization in Deep Neural Networks</strong></p>

<ul>
  <li>intro: Collective Residual Networks</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.02180">https://arxiv.org/abs/1703.02180</a></li>
  <li>github(MXNet): <a href="https://github.com/cypw/CRU-Net">https://github.com/cypw/CRU-Net</a></li>
</ul>

<p><strong>Residual Attention Network for Image Classification</strong></p>

<ul>
  <li>intro: CVPR 2017 Spotlight. SenseTime Group Limited &amp; Tsinghua University &amp; The Chinese University of Hong Kong</li>
  <li>intro: ImageNet (4.8% single model and single crop, top-5 error)</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1704.06904">https://arxiv.org/abs/1704.06904</a></li>
  <li>github(Caffe): <a href="https://github.com/buptwangfei/residual-attention-network">https://github.com/buptwangfei/residual-attention-network</a></li>
</ul>

<p><strong>Dilated Residual Networks</strong></p>

<ul>
  <li>intro: CVPR 2017. Princeton University &amp; Intel Labs</li>
  <li>keywords: Dilated Residual Networks (DRN)</li>
  <li>project page: <a href="http://vladlen.info/publications/dilated-residual-networks/">http://vladlen.info/publications/dilated-residual-networks/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.09914">https://arxiv.org/abs/1705.09914</a></li>
  <li>paper: <a href="http://vladlen.info/papers/DRN.pdf">http://vladlen.info/papers/DRN.pdf</a></li>
</ul>

<p><strong>Dynamic Steerable Blocks in Deep Residual Networks</strong></p>

<ul>
  <li>intro: University of Amsterdam &amp; ESAT-PSI</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.00598">https://arxiv.org/abs/1706.00598</a></li>
</ul>

<p><strong>Learning Deep ResNet Blocks Sequentially using Boosting Theory</strong></p>

<ul>
  <li>intro: Microsoft Research &amp; Princeton University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.04964">https://arxiv.org/abs/1706.04964</a></li>
</ul>

<h2 id="densenet">DenseNet</h2>

<p><strong>Densely Connected Convolutional Networks</strong></p>

<p><img src="https://cloud.githubusercontent.com/assets/8370623/17981496/fa648b32-6ad1-11e6-9625-02fdd72fdcd3.jpg" height="150" alt="" /></p>

<ul>
  <li>intro: CVPR 2017 best paper. Cornell University &amp; Tsinghua University. DenseNet</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.06993">http://arxiv.org/abs/1608.06993</a></li>
  <li>github: <a href="https://github.com/liuzhuang13/DenseNet">https://github.com/liuzhuang13/DenseNet</a></li>
  <li>github(Lasagne): <a href="https://github.com/Lasagne/Recipes/tree/master/papers/densenet">https://github.com/Lasagne/Recipes/tree/master/papers/densenet</a></li>
  <li>github(Keras): <a href="https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet">https://github.com/tdeboissiere/DeepLearningImplementations/tree/master/DenseNet</a></li>
  <li>github(Caffe): <a href="https://github.com/liuzhuang13/DenseNetCaffe">https://github.com/liuzhuang13/DenseNetCaffe</a></li>
  <li>github(Tensorflow): <a href="https://github.com/YixuanLi/densenet-tensorflow">https://github.com/YixuanLi/densenet-tensorflow</a></li>
  <li>github(Keras): <a href="https://github.com/titu1994/DenseNet">https://github.com/titu1994/DenseNet</a></li>
  <li>github(PyTorch): <a href="https://github.com/bamos/densenet.pytorch">https://github.com/bamos/densenet.pytorch</a></li>
  <li>github(PyTorch): <a href="https://github.com/andreasveit/densenet-pytorch">https://github.com/andreasveit/densenet-pytorch</a></li>
  <li>github(Tensorflow): <a href="https://github.com/ikhlestov/vision_networks">https://github.com/ikhlestov/vision_networks</a></li>
</ul>

<p><strong>Memory-Efficient Implementation of DenseNets</strong></p>

<ul>
  <li>intro: Cornell University &amp; Fudan University &amp; Facebook AI Research</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.06990">https://arxiv.org/abs/1707.06990</a></li>
  <li>github: <a href="https://github.com/liuzhuang13/DenseNet/tree/master/models">https://github.com/liuzhuang13/DenseNet/tree/master/models</a></li>
  <li>github: <a href="https://github.com/gpleiss/efficient_densenet_pytorch">https://github.com/gpleiss/efficient_densenet_pytorch</a></li>
  <li>github: <a href="https://github.com/taineleau/efficient_densenet_mxnet">https://github.com/taineleau/efficient_densenet_mxnet</a></li>
  <li>github: <a href="https://github.com/Tongcheng/DN_CaffeScript">https://github.com/Tongcheng/DN_CaffeScript</a></li>
</ul>

<h2 id="imagenet-projects">ImageNet Projects</h2>

<p><strong>Training an Object Classifier in Torch-7 on multiple GPUs over ImageNet</strong></p>

<ul>
  <li>intro: an imagenet example in torch</li>
  <li>github: <a href="https://github.com/soumith/imagenet-multiGPU.torch">https://github.com/soumith/imagenet-multiGPU.torch</a></li>
</ul>

<h1 id="deep-learning-and-bayesian">Deep Learning And Bayesian</h1>

<p><strong>Scalable Bayesian Optimization Using Deep Neural Networks</strong></p>

<ul>
  <li>intro: ICML 2015</li>
  <li>paper: <a href="http://jmlr.org/proceedings/papers/v37/snoek15.html">http://jmlr.org/proceedings/papers/v37/snoek15.html</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1502.05700">http://arxiv.org/abs/1502.05700</a></li>
  <li>github: <a href="https://github.com/bshahr/torch-dngo">https://github.com/bshahr/torch-dngo</a></li>
</ul>

<p><strong>Bayesian Dark Knowledge</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1506.04416">http://arxiv.org/abs/1506.04416</a></li>
  <li>notes: <a href="https://www.evernote.com/shard/s189/sh/92cc4cbf-285e-4038-af08-c6d9e4aee6ea/d505237e82dc81be9859bc82f3902f9f">Notes on Bayesian Dark Knowledge</a></li>
</ul>

<p><strong>Memory-based Bayesian Reasoning with Deep Learning</strong></p>

<ul>
  <li>intro: Google DeepMind</li>
  <li>slides: <a href="http://blog.shakirm.com/wp-content/uploads/2015/11/CSML_BayesDeep.pdf">http://blog.shakirm.com/wp-content/uploads/2015/11/CSML_BayesDeep.pdf</a></li>
</ul>

<p><strong>Towards Bayesian Deep Learning: A Survey</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1604.01662">http://arxiv.org/abs/1604.01662</a></li>
</ul>

<p><strong>Towards Bayesian Deep Learning: A Framework and Some Existing Methods</strong></p>

<ul>
  <li>intro: IEEE Transactions on Knowledge and Data Engineering (TKDE), 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.06884">http://arxiv.org/abs/1608.06884</a></li>
</ul>

<p><strong>Bayesian Deep Learning: Neural Networks in PyMC3 estimated with Variational Inference</strong></p>

<ul>
  <li>blog: <a href="http://blog.quantopian.com/bayesian-deep-learning/">http://blog.quantopian.com/bayesian-deep-learning/</a></li>
</ul>

<p><strong>Bayesian Deep Learning Part II: Bridging PyMC3 and Lasagne to build a Hierarchical Neural Network</strong></p>

<ul>
  <li>blog: <a href="http://twiecki.github.io/blog/2016/07/05/bayesian-deep-learning/">http://twiecki.github.io/blog/2016/07/05/bayesian-deep-learning/</a></li>
</ul>

<p><strong>Deep Learning: A Bayesian Perspective</strong></p>

<ul>
  <li>intro: George Mason University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.00473">https://arxiv.org/abs/1706.00473</a></li>
</ul>

<h1 id="semi-supervised-learning">Semi-Supervised Learning</h1>

<p><strong>Semi-Supervised Learning with Graphs</strong></p>

<ul>
  <li>intro: Label Propagation</li>
  <li>paper: <a href="http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf">http://pages.cs.wisc.edu/~jerryzhu/pub/thesis.pdf</a></li>
  <li>blog(“标签传播算法（Label Propagation）及Python实现”): <a href="http://blog.csdn.net/zouxy09/article/details/49105265">http://blog.csdn.net/zouxy09/article/details/49105265</a></li>
</ul>

<p><strong>Semi-Supervised Learning with Ladder Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1507.02672">http://arxiv.org/abs/1507.02672</a></li>
  <li>github: <a href="https://github.com/CuriousAI/ladder">https://github.com/CuriousAI/ladder</a></li>
  <li>github: <a href="https://github.com/rinuboney/ladder">https://github.com/rinuboney/ladder</a></li>
</ul>

<p><strong>Semi-supervised Feature Transfer: The Practical Benefit of Deep Learning Today?</strong></p>

<ul>
  <li>blog: <a href="http://www.kdnuggets.com/2016/07/semi-supervised-feature-transfer-deep-learning.html">http://www.kdnuggets.com/2016/07/semi-supervised-feature-transfer-deep-learning.html</a></li>
</ul>

<p><strong>Temporal Ensembling for Semi-Supervised Learning</strong></p>

<ul>
  <li>intro: ICLR 2017</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.02242">https://arxiv.org/abs/1610.02242</a></li>
  <li>github: <a href="https://github.com/smlaine2/tempens">https://github.com/smlaine2/tempens</a></li>
</ul>

<p><strong>Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data</strong></p>

<ul>
  <li>intro: ICLR 2017 best paper award</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.05755">https://arxiv.org/abs/1610.05755</a></li>
  <li>github: <a href="https://github.com/tensorflow/models/tree/8505222ea1f26692df05e65e35824c6c71929bb5/privacy">https://github.com/tensorflow/models/tree/8505222ea1f26692df05e65e35824c6c71929bb5/privacy</a></li>
</ul>

<p><strong>Infinite Variational Autoencoder for Semi-Supervised Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.07800">https://arxiv.org/abs/1611.07800</a></li>
</ul>

<h1 id="transfer-learning">Transfer Learning</h1>

<p><strong>Discriminative Transfer Learning with Tree-based Priors</strong></p>

<ul>
  <li>intro: NIPS 2013</li>
  <li>paper: <a href="http://deeplearning.net/wp-content/uploads/2013/03/icml13_workshop.pdf">http://deeplearning.net/wp-content/uploads/2013/03/icml13_workshop.pdf</a></li>
  <li>paper: <a href="http://www.cs.toronto.edu/~nitish/treebasedpriors.pdf">http://www.cs.toronto.edu/~nitish/treebasedpriors.pdf</a></li>
</ul>

<p><strong>How transferable are features in deep neural networks?</strong></p>

<ul>
  <li>intro: NIPS 2014</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1411.1792">http://arxiv.org/abs/1411.1792</a></li>
  <li>paper: <a href="http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf">http://papers.nips.cc/paper/5347-how-transferable-are-features-in-deep-neural-networks.pdf</a></li>
  <li>github: <a href="https://github.com/yosinski/convnet_transfer">https://github.com/yosinski/convnet_transfer</a></li>
</ul>

<p><strong>Learning and Transferring Mid-Level Image Representations using Convolutional Neural Networks</strong></p>

<ul>
  <li>paper: <a href="http://research.microsoft.com/pubs/214307/paper.pdf">http://research.microsoft.com/pubs/214307/paper.pdf</a></li>
</ul>

<p><strong>Transferring Knowledge from a RNN to a DNN</strong></p>

<ul>
  <li>intro: CMU</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1504.01483">https://arxiv.org/abs/1504.01483</a></li>
</ul>

<p><strong>Simultaneous Deep Transfer Across Domains and Tasks</strong></p>

<ul>
  <li>intro: ICCV 2015</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1510.02192">http://arxiv.org/abs/1510.02192</a></li>
</ul>

<p><strong>Net2Net: Accelerating Learning via Knowledge Transfer</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.05641">http://arxiv.org/abs/1511.05641</a></li>
  <li>github: <a href="https://github.com/soumith/net2net.torch">https://github.com/soumith/net2net.torch</a></li>
  <li>notes(by Hugo Larochelle): <a href="https://www.evernote.com/shard/s189/sh/46414718-9663-440e-bbb7-65126b247b42/19688c438709251d8275d843b8158b03">https://www.evernote.com/shard/s189/sh/46414718-9663-440e-bbb7-65126b247b42/19688c438709251d8275d843b8158b03</a></li>
</ul>

<p><strong>Transfer Learning from Deep Features for Remote Sensing and Poverty Mapping</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1510.00098">http://arxiv.org/abs/1510.00098</a></li>
</ul>

<p><strong>A theoretical framework for deep transfer learning</strong></p>

<ul>
  <li>key words: transfer learning, PAC learning, PAC-Bayesian, deep learning</li>
  <li>homepage: <a href="http://imaiai.oxfordjournals.org/content/early/2016/04/28/imaiai.iaw008">http://imaiai.oxfordjournals.org/content/early/2016/04/28/imaiai.iaw008</a></li>
  <li>paper: <a href="http://imaiai.oxfordjournals.org/content/early/2016/04/28/imaiai.iaw008.full.pdf">http://imaiai.oxfordjournals.org/content/early/2016/04/28/imaiai.iaw008.full.pdf</a></li>
</ul>

<p><strong>Transfer learning using neon</strong></p>

<ul>
  <li>blog: <a href="http://www.nervanasys.com/transfer-learning-using-neon/">http://www.nervanasys.com/transfer-learning-using-neon/</a></li>
</ul>

<p><strong>Hyperparameter Transfer Learning through Surrogate Alignment for Efficient Deep Neural Network Training</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.00218">http://arxiv.org/abs/1608.00218</a></li>
</ul>

<p><strong>What makes ImageNet good for transfer learning?</strong></p>

<ul>
  <li>project page: <a href="http://minyounghuh.com/papers/analysis/">http://minyounghuh.com/papers/analysis/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.08614">http://arxiv.org/abs/1608.08614</a></li>
</ul>

<p><strong>Fine-tuning a Keras model using Theano trained Neural Network &amp; Introduction to Transfer Learning</strong></p>

<ul>
  <li>github: <a href="https://www.analyticsvidhya.com/blog/2016/11/fine-tuning-a-keras-model-using-theano-trained-neural-network-introduction-to-transfer-learning/">https://www.analyticsvidhya.com/blog/2016/11/fine-tuning-a-keras-model-using-theano-trained-neural-network-introduction-to-transfer-learning/</a></li>
</ul>

<p><strong>Multi-source Transfer Learning with Convolutional Neural Networks for Lung Pattern Analysis</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.02589">https://arxiv.org/abs/1612.02589</a></li>
</ul>

<p><strong>Borrowing Treasures from the Wealthy: Deep Transfer Learning through Selective Joint Fine-tuning</strong></p>

<ul>
  <li>intro: CVPR 2017. The University of Hong Kong</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.08690">https://arxiv.org/abs/1702.08690</a></li>
</ul>

<h1 id="multi-label-learning">Multi-label Learning</h1>

<p><strong>CNN: Single-label to Multi-label</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1406.5726">http://arxiv.org/abs/1406.5726</a></li>
</ul>

<p><strong>Deep Learning for Multi-label Classification</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1502.05988">http://arxiv.org/abs/1502.05988</a></li>
  <li>github: <a href="http://meka.sourceforge.net">http://meka.sourceforge.net</a></li>
</ul>

<p><strong>Predicting Unseen Labels using Label Hierarchies in Large-Scale Multi-label Learning</strong></p>

<ul>
  <li>intro: ECML 2015</li>
  <li>paper: <a href="https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf">https://www.kdsl.tu-darmstadt.de/fileadmin/user_upload/Group_KDSL/PUnL_ECML2015_camera_ready.pdf</a></li>
</ul>

<p><strong>Learning with a Wasserstein Loss</strong></p>

<ul>
  <li>project page: <a href="http://cbcl.mit.edu/wasserstein/">http://cbcl.mit.edu/wasserstein/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1506.05439">http://arxiv.org/abs/1506.05439</a></li>
  <li>code: <a href="http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz">http://cbcl.mit.edu/wasserstein/yfcc100m_labels.tar.gz</a></li>
  <li>MIT news: <a href="http://news.mit.edu/2015/more-flexible-machine-learning-1001">http://news.mit.edu/2015/more-flexible-machine-learning-1001</a></li>
</ul>

<p><strong>From Softmax to Sparsemax: A Sparse Model of Attention and Multi-Label Classification</strong></p>

<ul>
  <li>intro: ICML 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.02068">http://arxiv.org/abs/1602.02068</a></li>
  <li>github: <a href="https://github.com/gokceneraslan/SparseMax.torch">https://github.com/gokceneraslan/SparseMax.torch</a></li>
  <li>github: <a href="https://github.com/Unbabel/sparsemax">https://github.com/Unbabel/sparsemax</a></li>
</ul>

<p><strong>CNN-RNN: A Unified Framework for Multi-label Image Classification</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1604.04573">http://arxiv.org/abs/1604.04573</a></li>
</ul>

<p><strong>Improving Multi-label Learning with Missing Labels by Structured Semantic Correlations</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.01441">http://arxiv.org/abs/1608.01441</a></li>
</ul>

<p><strong>Extreme Multi-label Loss Functions for Recommendation, Tagging, Ranking &amp; Other Missing Label Applications</strong></p>

<ul>
  <li>intro: Indian Institute of Technology Delhi &amp; MSR</li>
  <li>paper: <a href="https://manikvarma.github.io/pubs/jain16.pdf">https://manikvarma.github.io/pubs/jain16.pdf</a></li>
</ul>

<p><strong>Multi-Label Image Classification with Regional Latent Semantic Dependencies</strong></p>

<ul>
  <li>intro: Regional Latent Semantic Dependencies model (RLSD), RNN, RPN</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01082">https://arxiv.org/abs/1612.01082</a></li>
</ul>

<p><strong>Privileged Multi-label Learning</strong></p>

<ul>
  <li>intro: Peking University &amp; University of Technology Sydney &amp; University of Sydney</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.07194">https://arxiv.org/abs/1701.07194</a></li>
</ul>

<h1 id="multi-task-learning">Multi-task Learning</h1>

<p><strong>Multitask Learning / Domain Adaptation</strong></p>

<ul>
  <li>homepage: <a href="http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html">http://www.cs.cornell.edu/~kilian/research/multitasklearning/multitasklearning.html</a></li>
</ul>

<p><strong>multi-task learning</strong></p>

<ul>
  <li>discussion: <a href="https://github.com/memect/hao/issues/93">https://github.com/memect/hao/issues/93</a></li>
</ul>

<p><strong>Learning and Transferring Multi-task Deep Representation for Face Alignment</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1408.3967">http://arxiv.org/abs/1408.3967</a></li>
</ul>

<p><strong>Multi-task learning of facial landmarks and expression</strong></p>

<ul>
  <li>paper: <a href="http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf">http://www.uoguelph.ca/~gwtaylor/publications/gwtaylor_crv2014.pdf</a></li>
</ul>

<p><strong>Multi-Task Deep Visual-Semantic Embedding for Video Thumbnail Selection</strong></p>

<ul>
  <li>intro:  CVPR 2015</li>
  <li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Multi-Task_Deep_Visual-Semantic_2015_CVPR_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Liu_Multi-Task_Deep_Visual-Semantic_2015_CVPR_paper.pdf</a></li>
</ul>

<p><strong>Learning Multiple Tasks with Deep Relationship Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1506.02117">https://arxiv.org/abs/1506.02117</a></li>
</ul>

<p><strong>Learning deep representation of multityped objects and tasks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.01359">http://arxiv.org/abs/1603.01359</a></li>
</ul>

<p><strong>Cross-stitch Networks for Multi-task Learning</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1604.03539">http://arxiv.org/abs/1604.03539</a></li>
</ul>

<p><strong>Multi-Task Learning in Tensorflow (Part 1)</strong></p>

<ul>
  <li>blog: <a href="https://jg8610.github.io/Multi-Task/">https://jg8610.github.io/Multi-Task/</a></li>
</ul>

<p><strong>Deep Multi-Task Learning with Shared Memory</strong></p>

<ul>
  <li>intro: EMNLP 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.07222">http://arxiv.org/abs/1609.07222</a></li>
</ul>

<p><strong>Learning to Push by Grasping: Using multiple tasks for effective learning</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.09025">http://arxiv.org/abs/1609.09025</a></li>
</ul>

<p><strong>Identifying beneficial task relations for multi-task learning in deep neural networks</strong></p>

<ul>
  <li>intro: EACL 2017</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.08303">https://arxiv.org/abs/1702.08303</a></li>
  <li>github: <a href="https://github.com/jbingel/eacl2017_mtl">https://github.com/jbingel/eacl2017_mtl</a></li>
</ul>

<p><strong>Multi-Task Learning Using Uncertainty to Weigh Losses for Scene Geometry and Semantics</strong></p>

<ul>
  <li>intro: University of Cambridge</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.07115">https://arxiv.org/abs/1705.07115</a></li>
</ul>

<p><strong>One Model To Learn Them All</strong></p>

<ul>
  <li>intro: Google Brain &amp; University of Toronto</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.05137">https://arxiv.org/abs/1706.05137</a></li>
  <li>github: <a href="https://github.com/tensorflow/tensor2tensor">https://github.com/tensorflow/tensor2tensor</a></li>
</ul>

<p><strong>MultiModel: Multi-Task Machine Learning Across Domains</strong></p>

<p><a href="https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html">https://research.googleblog.com/2017/06/multimodel-multi-task-machine-learning.html</a></p>

<p><strong>An Overview of Multi-Task Learning in Deep Neural Networks</strong></p>

<ul>
  <li>intro: Aylien Ltd</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.05098">https://arxiv.org/abs/1706.05098</a></li>
</ul>

<h1 id="multi-modal-learning">Multi-modal Learning</h1>

<p><strong>Multimodal Deep Learning</strong></p>

<ul>
  <li>paper: <a href="http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf">http://ai.stanford.edu/~ang/papers/nipsdlufl10-MultimodalDeepLearning.pdf</a></li>
</ul>

<p><strong>Multimodal Convolutional Neural Networks for Matching Image and Sentence</strong></p>

<ul>
  <li>homepage: <a href="http://mcnn.noahlab.com.hk/project.html">http://mcnn.noahlab.com.hk/project.html</a></li>
  <li>paper: <a href="http://mcnn.noahlab.com.hk/ICCV2015.pdf">http://mcnn.noahlab.com.hk/ICCV2015.pdf</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1504.06063">http://arxiv.org/abs/1504.06063</a></li>
</ul>

<p><strong>A C++ library for Multimodal Deep Learning</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.06927">http://arxiv.org/abs/1512.06927</a></li>
  <li>github: <a href="https://github.com/Jian-23/Deep-Learning-Library">https://github.com/Jian-23/Deep-Learning-Library</a></li>
</ul>

<p><strong>Multimodal Learning for Image Captioning and Visual Question Answering</strong></p>

<ul>
  <li>slides: <a href="http://research.microsoft.com/pubs/264769/UCB_XiaodongHe.6.pdf">http://research.microsoft.com/pubs/264769/UCB_XiaodongHe.6.pdf</a></li>
</ul>

<p><strong>Multi modal retrieval and generation with deep distributed models</strong></p>

<ul>
  <li>slides: <a href="http://www.slideshare.net/roelofp/multi-modal-retrieval-and-generation-with-deep-distributed-models">http://www.slideshare.net/roelofp/multi-modal-retrieval-and-generation-with-deep-distributed-models</a></li>
  <li>slides: <a href="http://pan.baidu.com/s/1kUSjn4z">http://pan.baidu.com/s/1kUSjn4z</a></li>
</ul>

<p><strong>Learning Aligned Cross-Modal Representations from Weakly Aligned Data</strong></p>

<p><img src="http://projects.csail.mit.edu/cmplaces/imgs/teaser.png" alt="" height="300" /></p>

<ul>
  <li>homepage: <a href="http://projects.csail.mit.edu/cmplaces/index.html">http://projects.csail.mit.edu/cmplaces/index.html</a></li>
  <li>paper: <a href="http://projects.csail.mit.edu/cmplaces/content/paper.pdf">http://projects.csail.mit.edu/cmplaces/content/paper.pdf</a></li>
</ul>

<p><strong>Variational methods for Conditional Multimodal Deep Learning</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.01801">http://arxiv.org/abs/1603.01801</a></li>
</ul>

<p><strong>Training and Evaluating Multimodal Word Embeddings with Large-scale Web Annotated Images</strong></p>

<ul>
  <li>intro: NIPS 2016. University of California &amp; Pinterest</li>
  <li>project page: <a href="http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html">http://www.stat.ucla.edu/~junhua.mao/multimodal_embedding.html</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.08321">https://arxiv.org/abs/1611.08321</a></li>
</ul>

<p><strong>Deep Multi-Modal Image Correspondence Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01225">https://arxiv.org/abs/1612.01225</a></li>
</ul>

<p><strong>Multimodal Deep Learning (D4L4 Deep Learning for Speech and Language UPC 2017)</strong></p>

<ul>
  <li>slides: <a href="http://www.slideshare.net/xavigiro/multimodal-deep-learning-d4l4-deep-learning-for-speech-and-language-upc-2017">http://www.slideshare.net/xavigiro/multimodal-deep-learning-d4l4-deep-learning-for-speech-and-language-upc-2017</a></li>
</ul>

<h1 id="debugging-deep-learning">Debugging Deep Learning</h1>

<p><strong>Some tips for debugging deep learning</strong></p>

<ul>
  <li>blog: <a href="http://www.lab41.org/some-tips-for-debugging-in-deep-learning-2/">http://www.lab41.org/some-tips-for-debugging-in-deep-learning-2/</a></li>
</ul>

<p><strong>Introduction to debugging neural networks</strong></p>

<ul>
  <li>blog: <a href="http://russellsstewart.com/notes/0.html">http://russellsstewart.com/notes/0.html</a></li>
  <li>reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/4du7gv/introduction_to_debugging_neural_networks">https://www.reddit.com/r/MachineLearning/comments/4du7gv/introduction_to_debugging_neural_networks</a></li>
</ul>

<p><strong>How to Visualize, Monitor and Debug Neural Network Learning</strong></p>

<ul>
  <li>blog: <a href="http://deeplearning4j.org/visualization">http://deeplearning4j.org/visualization</a></li>
</ul>

<p><strong>Learning from learning curves</strong></p>

<ul>
  <li>intro: Kaggle</li>
  <li>blog: <a href="https://medium.com/@dsouza.amanda/learning-from-learning-curves-1a82c6f98f49#.o5synrvvl">https://medium.com/@dsouza.amanda/learning-from-learning-curves-1a82c6f98f49#.o5synrvvl</a></li>
</ul>

<h1 id="understanding-cnn">Understanding CNN</h1>

<p><strong>Understanding the Effective Receptive Field in Deep Convolutional Neural Networks</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>paper: <a href="http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf">http://www.cs.toronto.edu/~wenjie/papers/nips16/top.pdf</a></li>
</ul>

<h1 id="adversarial-examples-of-deep-learning">Adversarial Examples of Deep Learning</h1>

<p><strong>Intriguing properties of neural networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1312.6199">http://arxiv.org/abs/1312.6199</a></li>
</ul>

<p><strong>Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images</strong></p>

<ul>
  <li>intro: CVPR 2015</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1412.1897">http://arxiv.org/abs/1412.1897</a></li>
  <li>github: <a href="https://github.com/Evolving-AI-Lab/fooling/">https://github.com/Evolving-AI-Lab/fooling/</a></li>
</ul>

<p><strong>Explaining and Harnessing Adversarial Examples</strong></p>

<ul>
  <li>intro: primary cause of neural networks’ vulnerability to adversarial perturbation is their linear nature</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1412.6572">http://arxiv.org/abs/1412.6572</a></li>
</ul>

<p><strong>Distributional Smoothing with Virtual Adversarial Training</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1507.00677">http://arxiv.org/abs/1507.00677</a></li>
  <li>github: <a href="https://github.com/takerum/vat">https://github.com/takerum/vat</a></li>
</ul>

<p><strong>Confusing Deep Convolution Networks by Relabelling</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1510.06925v1">http://arxiv.org/abs/1510.06925v1</a></li>
</ul>

<p><strong>Exploring the Space of Adversarial Images</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1510.05328">http://arxiv.org/abs/1510.05328</a></li>
  <li>github: <a href="https://github.com/tabacof/adversarial">https://github.com/tabacof/adversarial</a></li>
</ul>

<p><strong>Learning with a Strong Adversary</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.03034">http://arxiv.org/abs/1511.03034</a></li>
</ul>

<p><strong>Adversarial examples in the physical world</strong></p>

<ul>
  <li>author: Alexey Kurakin, Ian Goodfellow, Samy Bengio. Google Brain &amp; OpenAI</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1607.02533">http://arxiv.org/abs/1607.02533</a></li>
</ul>

<p><strong>DeepFool: a simple and accurate method to fool deep neural networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.04599">http://arxiv.org/abs/1511.04599</a></li>
  <li>github: <a href="https://github.com/LTS4/DeepFool">https://github.com/LTS4/DeepFool</a></li>
</ul>

<p><strong>Adversarial Autoencoders</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.05644">http://arxiv.org/abs/1511.05644</a></li>
  <li>slides: <a href="https://docs.google.com/presentation/d/1Lyp91JOSzXo0Kk8gPdgyQUDuqLV_PnSzJh7i5c8ZKjs/edit?pref=2&amp;pli=1">https://docs.google.com/presentation/d/1Lyp91JOSzXo0Kk8gPdgyQUDuqLV_PnSzJh7i5c8ZKjs/edit?pref=2&amp;pli=1</a></li>
  <li>notes(by Dustin Tran): <a href="http://dustintran.com/blog/adversarial-autoencoders/">http://dustintran.com/blog/adversarial-autoencoders/</a></li>
  <li>TFD manifold: <a href="http://www.comm.utoronto.ca/~makhzani/adv_ae/tfd.gif">http://www.comm.utoronto.ca/~makhzani/adv_ae/tfd.gif</a></li>
  <li>SVHN style manifold: <a href="http://www.comm.utoronto.ca/~makhzani/adv_ae/svhn.gif">http://www.comm.utoronto.ca/~makhzani/adv_ae/svhn.gif</a></li>
</ul>

<p><strong>Understanding Adversarial Training: Increasing Local Stability of Neural Nets through Robust Optimization</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.05432">http://arxiv.org/abs/1511.05432</a></li>
  <li>github: <a href="https://github.com/yutaroyamada/RobustTraining">https://github.com/yutaroyamada/RobustTraining</a></li>
</ul>

<p><strong>(Deep Learning’s Deep Flaws)’s Deep Flaws (By Zachary Chase Lipton)</strong></p>

<ul>
  <li>blog: <a href="http://www.kdnuggets.com/2015/01/deep-learning-flaws-universal-machine-learning.html">http://www.kdnuggets.com/2015/01/deep-learning-flaws-universal-machine-learning.html</a></li>
</ul>

<p><strong>Deep Learning Adversarial Examples – Clarifying Misconceptions</strong></p>

<ul>
  <li>intro: By Ian Goodfellow, Google</li>
  <li>blog: <a href="http://www.kdnuggets.com/2015/07/deep-learning-adversarial-examples-misconceptions.html">http://www.kdnuggets.com/2015/07/deep-learning-adversarial-examples-misconceptions.html</a></li>
</ul>

<p><strong>Adversarial Machines: Fooling A.Is (and turn everyone into a Manga)</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/@samim/adversarial-machines-998d8362e996#.iv3muefgt">https://medium.com/@samim/adversarial-machines-998d8362e996#.iv3muefgt</a></li>
</ul>

<p><strong>How to trick a neural network into thinking a panda is a vulture</strong></p>

<ul>
  <li>blog: <a href="https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture">https://codewords.recurse.com/issues/five/why-do-neural-networks-think-a-panda-is-a-vulture</a></li>
</ul>

<p><strong>Assessing Threat of Adversarial Examples on Deep Neural Networks</strong></p>

<ul>
  <li>intro: pre-print version to appear in IEEE ICMLA 2016</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.04256">https://arxiv.org/abs/1610.04256</a></li>
</ul>

<p><strong>Safety Verification of Deep Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.06940">https://arxiv.org/abs/1610.06940</a></li>
</ul>

<p><strong>Adversarial Machine Learning at Scale</strong></p>

<ul>
  <li>intro: Google Brain &amp; OpenAI</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.01236">https://arxiv.org/abs/1611.01236</a></li>
</ul>

<p><strong>Feature Squeezing: Detecting Adversarial Examples in Deep Neural Networks</strong></p>

<p><a href="https://arxiv.org/abs/1704.01155">https://arxiv.org/abs/1704.01155</a></p>

<p><strong>Parseval Networks: Improving Robustness to Adversarial Examples</strong></p>

<ul>
  <li>intro: Facebook AI Research</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1704.08847">https://arxiv.org/abs/1704.08847</a></li>
</ul>

<p><strong>Towards Deep Learning Models Resistant to Adversarial Attacks</strong></p>

<ul>
  <li>intro: MIT</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.06083">https://arxiv.org/abs/1706.06083</a></li>
</ul>

<p><strong>NO Need to Worry about Adversarial Examples in Object Detection in Autonomous Vehicles</strong></p>

<ul>
  <li>intro: CVPR 2017 Spotlight Oral Workshop</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.03501">https://arxiv.org/abs/1707.03501</a></li>
</ul>

<h1 id="deep-learning-networks">Deep Learning Networks</h1>

<p><strong>PCANet: A Simple Deep Learning Baseline for Image Classification?</strong></p>

<ul>
  <li>arixv: <a href="http://arxiv.org/abs/1404.3606">http://arxiv.org/abs/1404.3606</a></li>
  <li>code(Matlab): <a href="http://mx.nthu.edu.tw/~tsunghan/download/PCANet_demo_pyramid.rar">http://mx.nthu.edu.tw/~tsunghan/download/PCANet_demo_pyramid.rar</a></li>
  <li>mirror: <a href="http://pan.baidu.com/s/1mg24b3a">http://pan.baidu.com/s/1mg24b3a</a></li>
  <li>github(C++): <a href="https://github.com/Ldpe2G/PCANet">https://github.com/Ldpe2G/PCANet</a></li>
  <li>github(Python): <a href="https://github.com/IshitaTakeshi/PCANet">https://github.com/IshitaTakeshi/PCANet</a></li>
</ul>

<p><strong>Convolutional Kernel Networks</strong></p>

<ul>
  <li>intro: NIPS 2014</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1406.3332">http://arxiv.org/abs/1406.3332</a></li>
</ul>

<p><strong>Deeply-supervised Nets</strong></p>

<ul>
  <li>intro: DSN</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1409.5185">http://arxiv.org/abs/1409.5185</a></li>
  <li>homepage: <a href="http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/">http://vcl.ucsd.edu/~sxie/2014/09/12/dsn-project/</a></li>
  <li>github: <a href="https://github.com/s9xie/DSN">https://github.com/s9xie/DSN</a></li>
  <li>notes: <a href="http://zhangliliang.com/2014/11/02/paper-note-dsn/">http://zhangliliang.com/2014/11/02/paper-note-dsn/</a></li>
</ul>

<p><strong>FitNets: Hints for Thin Deep Nets</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1412.6550">https://arxiv.org/abs/1412.6550</a></li>
  <li>github: <a href="https://github.com/adri-romsor/FitNets">https://github.com/adri-romsor/FitNets</a></li>
</ul>

<p><strong>Striving for Simplicity: The All Convolutional Net</strong></p>

<ul>
  <li>intro: ICLR-2015 workshop</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1412.6806">http://arxiv.org/abs/1412.6806</a></li>
</ul>

<p><strong>How these researchers tried something unconventional to come out with a smaller yet better Image Recognition.</strong></p>

<ul>
  <li>intro: All Convolutional Network: (https://arxiv.org/abs/1412.6806#) implementation in Keras</li>
  <li>blog: <a href="https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72#.pfdbvdmuh">https://medium.com/@matelabs_ai/how-these-researchers-tried-something-unconventional-to-came-out-with-a-smaller-yet-better-image-544327f30e72#.pfdbvdmuh</a></li>
  <li>blog: <a href="https://github.com/MateLabs/All-Conv-Keras">https://github.com/MateLabs/All-Conv-Keras</a></li>
</ul>

<p><strong>Pointer Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1506.03134">https://arxiv.org/abs/1506.03134</a></li>
  <li>github: <a href="https://github.com/vshallc/PtrNets">https://github.com/vshallc/PtrNets</a></li>
  <li>github(TensorFlow): <a href="https://github.com/ikostrikov/TensorFlow-Pointer-Networks">https://github.com/ikostrikov/TensorFlow-Pointer-Networks</a></li>
  <li>github(TensorFlow): <a href="https://github.com/devsisters/pointer-network-tensorflow">https://github.com/devsisters/pointer-network-tensorflow</a></li>
  <li>notes: <a href="https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/pointer-networks.md">https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/pointer-networks.md</a></li>
</ul>

<p><strong>Pointer Networks in TensorFlow (with sample code)</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264#.sxipqfj30">https://medium.com/@devnag/pointer-networks-in-tensorflow-with-sample-code-14645063f264#.sxipqfj30</a></li>
  <li>github: <a href="https://github.com/devnag/tensorflow-pointer-networks">https://github.com/devnag/tensorflow-pointer-networks</a></li>
</ul>

<p><strong>Rectified Factor Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1502.06464">http://arxiv.org/abs/1502.06464</a></li>
  <li>github: <a href="https://github.com/untom/librfn">https://github.com/untom/librfn</a></li>
</ul>

<p><strong>Correlational Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1504.07225">http://arxiv.org/abs/1504.07225</a></li>
  <li>github: <a href="https://github.com/apsarath/CorrNet">https://github.com/apsarath/CorrNet</a></li>
</ul>

<p><strong>Diversity Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.05077">http://arxiv.org/abs/1511.05077</a></li>
</ul>

<p><strong>Competitive Multi-scale Convolution</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.05635">http://arxiv.org/abs/1511.05635</a></li>
  <li>blog: <a href="https://zhuanlan.zhihu.com/p/22377389">https://zhuanlan.zhihu.com/p/22377389</a></li>
</ul>

<p><strong>A Unified Approach for Learning the Parameters of Sum-Product Networks (SPN)</strong></p>

<ul>
  <li>intro: “The Sum-Product Network (SPN) is a new type of machine learning model 
with fast exact probabilistic inference over many layers.”</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.00318">http://arxiv.org/abs/1601.00318</a></li>
  <li>homepage: <a href="http://spn.cs.washington.edu/index.shtml">http://spn.cs.washington.edu/index.shtml</a></li>
  <li>code: <a href="http://spn.cs.washington.edu/code.shtml">http://spn.cs.washington.edu/code.shtml</a></li>
</ul>

<p><strong>Awesome Sum-Product Networks</strong></p>

<ul>
  <li>github: <a href="https://github.com/arranger1044/awesome-spn">https://github.com/arranger1044/awesome-spn</a></li>
</ul>

<p><strong>Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation</strong></p>

<ul>
  <li>intro: CVPR 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.07356">http://arxiv.org/abs/1511.07356</a></li>
  <li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Honari_Recombinator_Networks_Learning_CVPR_2016_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Honari_Recombinator_Networks_Learning_CVPR_2016_paper.pdf</a></li>
  <li>github: <a href="https://github.com/SinaHonari/RCN">https://github.com/SinaHonari/RCN</a></li>
</ul>

<p><strong>Dynamic Capacity Networks</strong></p>

<ul>
  <li>intro: ICML 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.07838">http://arxiv.org/abs/1511.07838</a></li>
  <li>github(Tensorflow): <a href="https://github.com/beopst/dcn.tf">https://github.com/beopst/dcn.tf</a></li>
  <li>review: <a href="http://www.erogol.com/1314-2/">http://www.erogol.com/1314-2/</a></li>
</ul>

<p><strong>Bitwise Neural Networks</strong></p>

<ul>
  <li>paper: <a href="http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf">http://paris.cs.illinois.edu/pubs/minje-icmlw2015.pdf</a></li>
  <li>demo: <a href="http://minjekim.com/demo_bnn.html">http://minjekim.com/demo_bnn.html</a></li>
</ul>

<p><strong>Learning Discriminative Features via Label Consistent Neural Network</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.01168">http://arxiv.org/abs/1602.01168</a></li>
</ul>

<p><strong>A Theory of Generative ConvNet</strong></p>

<ul>
  <li>project page: <a href="http://www.stat.ucla.edu/~ywu/GenerativeConvNet/main.html">http://www.stat.ucla.edu/~ywu/GenerativeConvNet/main.html</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.03264">http://arxiv.org/abs/1602.03264</a></li>
  <li>code: <a href="http://www.stat.ucla.edu/~ywu/GenerativeConvNet/doc/code.zip">http://www.stat.ucla.edu/~ywu/GenerativeConvNet/doc/code.zip</a></li>
</ul>

<p><strong>How to Train Deep Variational Autoencoders and Probabilistic Ladder Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.02282">http://arxiv.org/abs/1602.02282</a></li>
</ul>

<p><strong>Group Equivariant Convolutional Networks (G-CNNs)</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.07576">http://arxiv.org/abs/1602.07576</a></li>
</ul>

<p><strong>Deep Spiking Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.08323">http://arxiv.org/abs/1602.08323</a></li>
  <li>github: <a href="https://github.com/petered/spiking-mlp">https://github.com/petered/spiking-mlp</a></li>
</ul>

<p><strong>Low-rank passthrough neural networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.03116">http://arxiv.org/abs/1603.03116</a></li>
  <li>github: <a href="https://github.com/Avmb/lowrank-gru">https://github.com/Avmb/lowrank-gru</a></li>
</ul>

<p><strong>Single Image 3D Interpreter Network</strong></p>

<ul>
  <li>intro: ECCV 2016 (oral)</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1604.08685">https://arxiv.org/abs/1604.08685</a></li>
</ul>

<p><strong>Deeply-Fused Nets</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.07716">http://arxiv.org/abs/1605.07716</a></li>
</ul>

<p><strong>SNN: Stacked Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.08512">http://arxiv.org/abs/1605.08512</a></li>
</ul>

<p><strong>Universal Correspondence Network</strong></p>

<ul>
  <li>intro: NIPS 2016 full oral presentation. Stanford University &amp; NEC Laboratories America</li>
  <li>project page: <a href="http://cvgl.stanford.edu/projects/ucn/">http://cvgl.stanford.edu/projects/ucn/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1606.03558">https://arxiv.org/abs/1606.03558</a></li>
</ul>

<p><strong>Progressive Neural Networks</strong></p>

<ul>
  <li>intro: Google DeepMind</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1606.04671">https://arxiv.org/abs/1606.04671</a></li>
  <li>github: <a href="https://github.com/synpon/prog_nn">https://github.com/synpon/prog_nn</a></li>
  <li>github: <a href="https://github.com/yao62995/A3C">https://github.com/yao62995/A3C</a></li>
</ul>

<p><strong>Holistic SparseCNN: Forging the Trident of Accuracy, Speed, and Size</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.01409">http://arxiv.org/abs/1608.01409</a></li>
</ul>

<p><strong>Mollifying Networks</strong></p>

<ul>
  <li>author: Caglar Gulcehre, Marcin Moczulski, Francesco Visin, Yoshua Bengio</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.04980">http://arxiv.org/abs/1608.04980</a></li>
</ul>

<p><strong>Domain Separation Networks</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1608.06019">https://arxiv.org/abs/1608.06019</a></li>
  <li>github: <a href="https://github.com/tensorflow/models/tree/master/domain_adaptation">https://github.com/tensorflow/models/tree/master/domain_adaptation</a></li>
</ul>

<p><strong>Local Binary Convolutional Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.06049">http://arxiv.org/abs/1608.06049</a></li>
</ul>

<p><strong>CliqueCNN: Deep Unsupervised Exemplar Learning</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.08792">http://arxiv.org/abs/1608.08792</a></li>
  <li>github: <a href="https://github.com/asanakoy/cliquecnn">https://github.com/asanakoy/cliquecnn</a></li>
</ul>

<p><strong>Convexified Convolutional Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.01000">http://arxiv.org/abs/1609.01000</a></li>
</ul>

<p><strong>Multi-scale brain networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.08828">http://arxiv.org/abs/1608.08828</a></li>
</ul>

<p><strong>Warped Convolutions: Efficient Invariance to Spatial Transformations</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.04382">http://arxiv.org/abs/1609.04382</a></li>
</ul>

<p><strong>Input Convex Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.07152">http://arxiv.org/abs/1609.07152</a></li>
  <li>github: <a href="https://github.com/locuslab/icnn">https://github.com/locuslab/icnn</a></li>
</ul>

<p><strong>HyperNetworks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1609.09106">https://arxiv.org/abs/1609.09106</a></li>
  <li>blog: <a href="http://blog.otoro.net/2016/09/28/hyper-networks/">http://blog.otoro.net/2016/09/28/hyper-networks/</a></li>
  <li>github: <a href="https://github.com/hardmaru/supercell/blob/master/assets/MNIST_Static_HyperNetwork_Example.ipynb">https://github.com/hardmaru/supercell/blob/master/assets/MNIST_Static_HyperNetwork_Example.ipynb</a></li>
</ul>

<p><strong>HyperLSTM</strong></p>

<ul>
  <li>github: <a href="https://github.com/hardmaru/supercell/blob/master/supercell.py">https://github.com/hardmaru/supercell/blob/master/supercell.py</a></li>
</ul>

<p><strong>X-CNN: Cross-modal Convolutional Neural Networks for Sparse Datasets</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.00163">https://arxiv.org/abs/1610.00163</a></li>
</ul>

<p><strong>Tensor Switching Networks</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>arixiv: <a href="https://arxiv.org/abs/1610.10087">https://arxiv.org/abs/1610.10087</a></li>
  <li>github: <a href="https://github.com/coxlab/tsnet">https://github.com/coxlab/tsnet</a></li>
</ul>

<p><strong>BranchyNet: Fast Inference via Early Exiting from Deep Neural Networks</strong></p>

<ul>
  <li>intro: Harvard University</li>
  <li>paper: <a href="http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf">http://www.eecs.harvard.edu/~htk/publication/2016-icpr-teerapittayanon-mcdanel-kung.pdf</a></li>
  <li>github: <a href="https://github.com/kunglab/branchynet">https://github.com/kunglab/branchynet</a></li>
</ul>

<p><strong>Spectral Convolution Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.05378">https://arxiv.org/abs/1611.05378</a></li>
</ul>

<p><strong>DelugeNets: Deep Networks with Massive and Flexible Cross-layer Information Inflows</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.05552">https://arxiv.org/abs/1611.05552</a></li>
  <li>github: <a href="https://github.com/xternalz/DelugeNets">https://github.com/xternalz/DelugeNets</a></li>
</ul>

<p><strong>PolyNet: A Pursuit of Structural Diversity in Very Deep Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.05725">https://arxiv.org/abs/1611.05725</a></li>
  <li>poster: <a href="http://mmlab.ie.cuhk.edu.hk/projects/cu_deeplink/polynet_poster.pdf">http://mmlab.ie.cuhk.edu.hk/projects/cu_deeplink/polynet_poster.pdf</a></li>
</ul>

<p><strong>Weakly Supervised Cascaded Convolutional Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.08258">https://arxiv.org/abs/1611.08258</a></li>
</ul>

<p><strong>DeepSetNet: Predicting Sets with Deep Neural Networks</strong></p>

<ul>
  <li>intro: multi-class image classification and pedestrian detection</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.08998">https://arxiv.org/abs/1611.08998</a></li>
</ul>

<p><strong>Steerable CNNs</strong></p>

<ul>
  <li>intro: University of Amsterdam</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.08498">https://arxiv.org/abs/1612.08498</a></li>
</ul>

<p><strong>Feedback Networks</strong></p>

<ul>
  <li>project page: <a href="http://feedbacknet.stanford.edu/">http://feedbacknet.stanford.edu/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.09508">https://arxiv.org/abs/1612.09508</a></li>
  <li>youtube: <a href="https://youtu.be/MY5Uhv38Ttg">https://youtu.be/MY5Uhv38Ttg</a></li>
</ul>

<p><strong>Oriented Response Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.01833">https://arxiv.org/abs/1701.01833</a></li>
</ul>

<p><strong>OptNet: Differentiable Optimization as a Layer in Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.00443">https://arxiv.org/abs/1703.00443</a></li>
  <li>github: <a href="https://github.com/locuslab/optnet">https://github.com/locuslab/optnet</a></li>
</ul>

<p><strong>A fast and differentiable QP solver for PyTorch</strong></p>

<ul>
  <li>github: <a href="https://github.com/locuslab/qpth">https://github.com/locuslab/qpth</a></li>
</ul>

<p><strong>Meta Networks</strong></p>

<p><a href="https://arxiv.org/abs/1703.00837">https://arxiv.org/abs/1703.00837</a></p>

<p><strong>Deformable Convolutional Networks</strong></p>

<ul>
  <li>intro: Microsoft Research Asia</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.06211">https://arxiv.org/abs/1703.06211</a></li>
  <li>github(official): <a href="https://github.com/msracver/Deformable-ConvNets">https://github.com/msracver/Deformable-ConvNets</a></li>
  <li>github: <a href="https://github.com/felixlaumon/deform-conv">https://github.com/felixlaumon/deform-conv</a></li>
  <li>github: <a href="https://github.com/oeway/pytorch-deform-conv">https://github.com/oeway/pytorch-deform-conv</a></li>
</ul>

<p><strong>Second-order Convolutional Neural Networks</strong></p>

<p><a href="https://arxiv.org/abs/1703.06817">https://arxiv.org/abs/1703.06817</a></p>

<p><strong>Gabor Convolutional Networks</strong></p>

<p><a href="https://arxiv.org/abs/1705.01450">https://arxiv.org/abs/1705.01450</a></p>

<p><strong>Deep Rotation Equivariant Network</strong></p>

<p><a href="https://arxiv.org/abs/1705.08623">https://arxiv.org/abs/1705.08623</a></p>

<p><strong>Dense Transformer Networks</strong></p>

<ul>
  <li>intro: Washington State University &amp; University of California, Davis</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.08881">https://arxiv.org/abs/1705.08881</a></li>
  <li>github: <a href="https://github.com/divelab/dtn">https://github.com/divelab/dtn</a></li>
</ul>

<p><strong>Deep Complex Networks</strong></p>

<ul>
  <li>intro: [Université de Montréal &amp; INRS-EMT &amp; Microsoft Maluuba</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.09792">https://arxiv.org/abs/1705.09792</a></li>
  <li>github: <a href="https://github.com/ChihebTrabelsi/deep_complex_networks">https://github.com/ChihebTrabelsi/deep_complex_networks</a></li>
</ul>

<p><strong>DiracNets: Training Very Deep Neural Networks Without Skip-Connections</strong></p>

<ul>
  <li>intro: Université Paris-Est</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.00388">https://arxiv.org/abs/1706.00388</a></li>
  <li>github: <a href="https://github.com/szagoruyko/diracnets">https://github.com/szagoruyko/diracnets</a></li>
</ul>

<p><strong>Dual Path Networks</strong></p>

<ul>
  <li>intro: National University of Singapore</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.01629">https://arxiv.org/abs/1707.01629</a></li>
  <li>github(MXNet): <a href="https://github.com/cypw/DPNs">https://github.com/cypw/DPNs</a></li>
</ul>

<p><strong>Primal-Dual Group Convolutions for Deep Neural Networks</strong></p>

<p><a href="https://arxiv.org/abs/1707.02725">https://arxiv.org/abs/1707.02725</a></p>

<p><strong>Sensor Transformation Attention Networks</strong></p>

<p><a href="https://arxiv.org/abs/1708.01015">https://arxiv.org/abs/1708.01015</a></p>

<h2 id="highway-networks">Highway Networks</h2>

<p><strong>Highway Networks</strong></p>

<ul>
  <li>intro: ICML 2015 Deep Learning workshop</li>
  <li>intro: shortcut connections with gating functions. These gates are data-dependent and have parameters</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1505.00387">http://arxiv.org/abs/1505.00387</a></li>
  <li>github(PyTorch): <a href="https://github.com/analvikingur/pytorch_Highway">https://github.com/analvikingur/pytorch_Highway</a></li>
</ul>

<p><strong>Highway Networks with TensorFlow</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6">https://medium.com/jim-fleming/highway-networks-with-tensorflow-1e6dfa667daa#.71fgztsb6</a></li>
</ul>

<p><strong>Very Deep Learning with Highway Networks</strong></p>

<ul>
  <li>homepage(papers+code+FAQ): <a href="http://people.idsia.ch/~rupesh/very_deep_learning/">http://people.idsia.ch/~rupesh/very_deep_learning/</a></li>
</ul>

<p><strong>Training Very Deep Networks</strong></p>

<ul>
  <li>intro: Extends <a href="https://arxiv.org/abs/1505.00387">Highway Networks</a></li>
  <li>project page: <a href="http://people.idsia.ch/~rupesh/very_deep_learning/">http://people.idsia.ch/~rupesh/very_deep_learning/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1507.06228">http://arxiv.org/abs/1507.06228</a></li>
</ul>

<h2 id="spatial-transformer-networks">Spatial Transformer Networks</h2>

<p><strong>Spatial Transformer Networks</strong></p>

<p><img src="https://camo.githubusercontent.com/bb81d6267f2123d59979453526d958a58899bb4f/687474703a2f2f692e696d6775722e636f6d2f4578474456756c2e706e67" height="300" alt="" /></p>

<ul>
  <li>intro: NIPS 2015</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1506.02025">http://arxiv.org/abs/1506.02025</a></li>
  <li>gitxiv: <a href="http://gitxiv.com/posts/5WTXTLuEA4Hd8W84G/spatial-transformer-networks">http://gitxiv.com/posts/5WTXTLuEA4Hd8W84G/spatial-transformer-networks</a></li>
  <li>github: <a href="https://github.com/daerduoCarey/SpatialTransformerLayer">https://github.com/daerduoCarey/SpatialTransformerLayer</a></li>
  <li>github: <a href="https://github.com/qassemoquab/stnbhwd">https://github.com/qassemoquab/stnbhwd</a></li>
  <li>github: <a href="https://github.com/skaae/transformer_network">https://github.com/skaae/transformer_network</a></li>
  <li>github(Caffe): <a href="https://github.com/happynear/SpatialTransformerLayer">https://github.com/happynear/SpatialTransformerLayer</a></li>
  <li>github: <a href="https://github.com/daviddao/spatial-transformer-tensorflow">https://github.com/daviddao/spatial-transformer-tensorflow</a></li>
  <li>caffe-issue: <a href="https://github.com/BVLC/caffe/issues/3114">https://github.com/BVLC/caffe/issues/3114</a></li>
  <li>code: <a href="https://lasagne.readthedocs.org/en/latest/modules/layers/special.html#lasagne.layers.TransformerLayer">https://lasagne.readthedocs.org/en/latest/modules/layers/special.html#lasagne.layers.TransformerLayer</a></li>
  <li>ipn(Lasagne): <a href="http://nbviewer.jupyter.org/github/Lasagne/Recipes/blob/master/examples/spatial_transformer_network.ipynb">http://nbviewer.jupyter.org/github/Lasagne/Recipes/blob/master/examples/spatial_transformer_network.ipynb</a></li>
  <li>notes: <a href="https://www.evernote.com/shard/s189/sh/ad8a38de-9e98-4e06-b09e-574bd62893ff/32f72798c095dd7672f4cb017a32d9b4">https://www.evernote.com/shard/s189/sh/ad8a38de-9e98-4e06-b09e-574bd62893ff/32f72798c095dd7672f4cb017a32d9b4</a></li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=6NOQC_fl1hQ">https://www.youtube.com/watch?v=6NOQC_fl1hQ</a></li>
</ul>

<p><strong>The power of Spatial Transformer Networks</strong></p>

<ul>
  <li>blog: <a href="http://torch.ch/blog/2015/09/07/spatial_transformers.html">http://torch.ch/blog/2015/09/07/spatial_transformers.html</a></li>
  <li>github: <a href="https://github.com/moodstocks/gtsrb.torch">https://github.com/moodstocks/gtsrb.torch</a></li>
</ul>

<p><strong>Recurrent Spatial Transformer Networks</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1509.05329">http://arxiv.org/abs/1509.05329</a></li>
</ul>

<p><strong>Deep Learning Paper Implementations: Spatial Transformer Networks - Part I</strong></p>

<ul>
  <li>blog: <a href="https://kevinzakka.github.io/2017/01/10/stn-part1/">https://kevinzakka.github.io/2017/01/10/stn-part1/</a></li>
  <li>github: <a href="https://github.com/kevinzakka/blog-code/tree/master/spatial_transformer">https://github.com/kevinzakka/blog-code/tree/master/spatial_transformer</a></li>
</ul>

<h2 id="fractalnet">FractalNet</h2>

<p><strong>FractalNet: Ultra-Deep Neural Networks without Residuals</strong></p>

<p><img src="http://people.cs.uchicago.edu/~larsson/fractalnet/overview.png" height="300" alt="" /></p>

<ul>
  <li>project: <a href="http://people.cs.uchicago.edu/~larsson/fractalnet/">http://people.cs.uchicago.edu/~larsson/fractalnet/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.07648">http://arxiv.org/abs/1605.07648</a></li>
  <li>github: <a href="https://github.com/gustavla/fractalnet">https://github.com/gustavla/fractalnet</a></li>
  <li>github: <a href="https://github.com/edgelord/FractalNet">https://github.com/edgelord/FractalNet</a></li>
  <li>github(Keras): <a href="https://github.com/snf/keras-fractalnet">https://github.com/snf/keras-fractalnet</a></li>
</ul>

<h2 id="graph-convolutional-networks">Graph Convolutional Networks</h2>

<p><strong>Learning Convolutional Neural Networks for Graphs</strong></p>

<ul>
  <li>intro: ICML 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.05273">http://arxiv.org/abs/1605.05273</a></li>
</ul>

<p><strong>Convolutional Neural Networks on Graphs with Fast Localized Spectral Filtering</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1606.09375">https://arxiv.org/abs/1606.09375</a></li>
  <li>github: <a href="https://github.com/mdeff/cnn_graph">https://github.com/mdeff/cnn_graph</a></li>
  <li>github: <a href="https://github.com/pfnet-research/chainer-graph-cnn">https://github.com/pfnet-research/chainer-graph-cnn</a></li>
</ul>

<p><strong>Semi-Supervised Classification with Graph Convolutional Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.02907">http://arxiv.org/abs/1609.02907</a></li>
  <li>github: <a href="https://github.com/tkipf/gcn">https://github.com/tkipf/gcn</a></li>
  <li>blog: <a href="http://tkipf.github.io/graph-convolutional-networks/">http://tkipf.github.io/graph-convolutional-networks/</a></li>
</ul>

<p><strong>Graph Based Convolutional Neural Network</strong></p>

<ul>
  <li>intro: BMVC 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.08965">http://arxiv.org/abs/1609.08965</a></li>
</ul>

<p><strong>How powerful are Graph Convolutions? (review of Kipf &amp; Welling, 2016)</strong></p>

<p><a href="http://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/">http://www.inference.vc/how-powerful-are-graph-convolutions-review-of-kipf-welling-2016-2/</a></p>

<p><strong>Graph Convolutional Networks</strong></p>

<p><img src="http://tkipf.github.io/graph-convolutional-networks/images/gcn_web.png" height="300" alt="" /></p>

<ul>
  <li>blog: <a href="http://tkipf.github.io/graph-convolutional-networks/">http://tkipf.github.io/graph-convolutional-networks/</a></li>
</ul>

<p><strong>DeepGraph: Graph Structure Predicts Network Growth</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.06251">https://arxiv.org/abs/1610.06251</a></li>
</ul>

<p><strong>Deep Learning with Sets and Point Clouds</strong></p>

<ul>
  <li>intro: CMU</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.04500">https://arxiv.org/abs/1611.04500</a></li>
</ul>

<p><strong>Deep Learning on Graphs</strong></p>

<ul>
  <li>lecture: <a href="https://figshare.com/articles/Deep_Learning_on_Graphs/4491686">https://figshare.com/articles/Deep_Learning_on_Graphs/4491686</a></li>
</ul>

<p><strong>Robust Spatial Filtering with Graph Convolutional Neural Networks</strong></p>

<p><a href="https://arxiv.org/abs/1703.00792">https://arxiv.org/abs/1703.00792</a></p>

<p><strong>Modeling Relational Data with Graph Convolutional Networks</strong></p>

<p><a href="https://arxiv.org/abs/1703.06103">https://arxiv.org/abs/1703.06103</a></p>

<p><strong>Distance Metric Learning using Graph Convolutional Networks: Application to Functional Brain Networks</strong></p>

<ul>
  <li>intro: Imperial College London</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.02161">https://arxiv.org/abs/1703.02161</a></li>
</ul>

<p><strong>Deep Learning on Graphs with Graph Convolutional Networks</strong></p>

<ul>
  <li>slides: <a href="http://tkipf.github.io/misc/GCNSlides.pdf">http://tkipf.github.io/misc/GCNSlides.pdf</a></li>
</ul>

<p><strong>Deep Learning on Graphs with Keras</strong></p>

<ul>
  <li>intro:; Keras implementation of Graph Convolutional Networks</li>
  <li>github: <a href="https://github.com/tkipf/keras-gcn">https://github.com/tkipf/keras-gcn</a></li>
</ul>

<h1 id="deep-learning-with-traditional-machine-learning-methods">Deep Learning with Traditional Machine Learning Methods</h1>

<h2 id="bag-of-words-bow">Bag of Words (BoW)</h2>

<p><strong>Deep Learning Transcends the Bag of Words</strong></p>

<ul>
  <li>blog: <a href="http://www.kdnuggets.com/2015/12/deep-learning-outgrows-bag-words-recurrent-neural-networks.html">http://www.kdnuggets.com/2015/12/deep-learning-outgrows-bag-words-recurrent-neural-networks.html</a></li>
</ul>

<h2 id="boosting">Boosting</h2>

<p><strong>Deep Boosting</strong></p>

<ul>
  <li>intro: ICML 2014</li>
  <li>paper: <a href="http://www.cs.princeton.edu/~usyed/CortesMohriSyedICML2014.pdf">http://www.cs.princeton.edu/~usyed/CortesMohriSyedICML2014.pdf</a></li>
  <li>github: <a href="https://github.com/google/deepboost">https://github.com/google/deepboost</a></li>
</ul>

<p><strong>Deep Incremental Boosting</strong></p>

<p><a href="https://arxiv.org/abs/1708.03704">https://arxiv.org/abs/1708.03704</a></p>

<h2 id="bootstrap">Bootstrap</h2>

<p><strong>Training Deep Neural Networks on Noisy Labels with Bootstrapping</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1412.6596">http://arxiv.org/abs/1412.6596</a></li>
</ul>

<h2 id="conditional-random-fields">Conditional Random Fields</h2>

<p><strong>DeepCRF: Neural Networks and CRFs for Sequence Labeling</strong></p>

<ul>
  <li>intro: A implementation of Conditional Random Fields (CRFs) with Deep Learning Method</li>
  <li>github: <a href="https://github.com/aonotas/deep-crf">https://github.com/aonotas/deep-crf</a></li>
</ul>

<h2 id="decision-tree">Decision Tree</h2>

<p><strong>Deep Neural Decision Forests</strong></p>

<ul>
  <li>intro: ICCV 2015. Microsoft Research. ICCV’15 Marr Prize</li>
  <li>paper: <a href="http://research.microsoft.com/pubs/255952/ICCV15_DeepNDF_main.pdf">http://research.microsoft.com/pubs/255952/ICCV15_DeepNDF_main.pdf</a></li>
  <li>slides: <a href="https://docs.google.com/presentation/d/1Ze7BAiWbMPyF0ax36D-aK00VfaGMGvvgD_XuANQW1gU/edit#slide=id.p">https://docs.google.com/presentation/d/1Ze7BAiWbMPyF0ax36D-aK00VfaGMGvvgD_XuANQW1gU/edit#slide=id.p</a></li>
  <li>github: <a href="https://github.com/chrischoy/fully-differentiable-deep-ndf-tf">https://github.com/chrischoy/fully-differentiable-deep-ndf-tf</a></li>
  <li>supplement: <a href="http://research.microsoft.com/pubs/255952/ICCV15_DeepNDF_suppl.pdf">http://research.microsoft.com/pubs/255952/ICCV15_DeepNDF_suppl.pdf</a></li>
  <li>notes: <a href="http://pan.baidu.com/s/1jGRWem6">http://pan.baidu.com/s/1jGRWem6</a></li>
</ul>

<p><strong>Neural Network and Decision Tree</strong></p>

<ul>
  <li>blog: <a href="http://rotationsymmetry.github.io/2015/07/18/neural-network-decision-tree/">http://rotationsymmetry.github.io/2015/07/18/neural-network-decision-tree/</a></li>
</ul>

<p><strong>Decision Forests, Convolutional Networks and the Models in-Between</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.01250">http://arxiv.org/abs/1603.01250</a></li>
  <li>notes: <a href="http://blog.csdn.net/stdcoutzyx/article/details/50993124">http://blog.csdn.net/stdcoutzyx/article/details/50993124</a></li>
</ul>

<h2 id="dictionary-learning">Dictionary Learning</h2>

<p><strong>Greedy Deep Dictionary Learning</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.00203">http://arxiv.org/abs/1602.00203</a></li>
</ul>

<p><strong>Sparse Factorization Layers for Neural Networks with Limited Supervision</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.04468">https://arxiv.org/abs/1612.04468</a></li>
</ul>

<h2 id="fisher-vectors">Fisher Vectors</h2>

<p><strong>Backpropagation Training for Fisher Vectors within Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.02549">https://arxiv.org/abs/1702.02549</a></li>
</ul>

<h2 id="gaussian-processes">Gaussian Processes</h2>

<p><strong>Questions on Deep Gaussian Processes</strong></p>

<ul>
  <li>blog: <a href="http://inverseprobability.com/2015/02/28/questions-on-deep-gaussian-processes/">http://inverseprobability.com/2015/02/28/questions-on-deep-gaussian-processes/</a></li>
</ul>

<p><strong>Qs – Deep Gaussian Processes</strong></p>

<p><img src="https://www.opendatascience.com/wp-content/uploads/2016/05/Gaussian.jpg" height="300" alt="" /></p>

<ul>
  <li>blog: <a href="https://www.opendatascience.com/blog/qs-deep-gaussian-processes/">https://www.opendatascience.com/blog/qs-deep-gaussian-processes/</a></li>
</ul>

<p><strong>Practical Learning of Deep Gaussian Processes via Random Fourier Features</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.04386">https://arxiv.org/abs/1610.04386</a></li>
</ul>

<p><strong>Deep Learning with Gaussian Process</strong></p>

<ul>
  <li>blog: <a href="https://amundtveit.com/2016/12/02/deep-learning-with-gaussian-process/">https://amundtveit.com/2016/12/02/deep-learning-with-gaussian-process/</a></li>
</ul>

<p><strong>Doubly Stochastic Variational Inference for Deep Gaussian Processes</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.08933">https://arxiv.org/abs/1705.08933</a></li>
  <li>github: <a href="https://github.com/thangbui/deepGP_approxEP">https://github.com/thangbui/deepGP_approxEP</a></li>
  <li>github: <a href="https://github.com/ICL-SML/Doubly-Stochastic-DGP">https://github.com/ICL-SML/Doubly-Stochastic-DGP</a></li>
</ul>

<h2 id="hmm">HMM</h2>

<p><strong>Unsupervised Neural Hidden Markov Models</strong></p>

<ul>
  <li>intro: EMNLP 2016</li>
  <li>paper: <a href="http://www.isi.edu/natural-language/mt/neural-hmm16.pdf">http://www.isi.edu/natural-language/mt/neural-hmm16.pdf</a></li>
  <li>github: <a href="https://github.com/ketranm/neuralHMM">https://github.com/ketranm/neuralHMM</a></li>
</ul>

<h2 id="kernel-methods">Kernel Methods</h2>

<p><strong>Kernel Methods for Deep Learning</strong></p>

<ul>
  <li>intro: NIPS 2009</li>
  <li>paper: <a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning">https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning</a></li>
  <li>paper: <a href="http://cseweb.ucsd.edu/~saul/papers/nips09_kernel.pdf">http://cseweb.ucsd.edu/~saul/papers/nips09_kernel.pdf</a></li>
</ul>

<p><strong>Deep Kernel Learning</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.02222">http://arxiv.org/abs/1511.02222</a></li>
</ul>

<p><strong>Stochastic Variational Deep Kernel Learning</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00336">https://arxiv.org/abs/1611.00336</a></li>
  <li>code: <a href="https://people.orie.cornell.edu/andrew/code/#SVDKL">https://people.orie.cornell.edu/andrew/code/#SVDKL</a></li>
</ul>

<p><strong>A Deep Learning Approach To Multiple Kernel Fusion</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.09007">https://arxiv.org/abs/1612.09007</a></li>
</ul>

<h2 id="svm">SVM</h2>

<p><strong>Large-scale Learning with SVM and Convolutional for Generic Object Categorization</strong></p>

<ul>
  <li>paper: <a href="http://yann.lecun.com/exdb/publis/pdf/huang-lecun-06.pdf">http://yann.lecun.com/exdb/publis/pdf/huang-lecun-06.pdf</a></li>
</ul>

<p><strong>Convolutional Neural Support Vector Machines:Hybrid Visual Pattern Classifiers for Multi-robot Systems</strong></p>

<ul>
  <li>paper: <a href="http://people.idsia.ch/~nagi/conferences/idsia/icmla2012.pdf">http://people.idsia.ch/~nagi/conferences/idsia/icmla2012.pdf</a></li>
</ul>

<p><strong>Deep Learning using Linear Support Vector Machines</strong></p>

<ul>
  <li>intro: Workshop on Representational Learning, ICML 2013</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1306.0239">https://arxiv.org/abs/1306.0239</a></li>
  <li>paper: <a href="http://deeplearning.net/wp-content/uploads/2013/03/dlsvm.pdf">http://deeplearning.net/wp-content/uploads/2013/03/dlsvm.pdf</a></li>
  <li>github: <a href="https://github.com/momer/deep-learning-faces">https://github.com/momer/deep-learning-faces</a></li>
  <li>code: <a href="https://code.google.com/p/deeplearning-faces/">https://code.google.com/p/deeplearning-faces/</a></li>
</ul>

<p><strong>Deep Support Vector Machines</strong></p>

<ul>
  <li>video: <a href="http://videolectures.net/roks2013_wiering_vector/">http://videolectures.net/roks2013_wiering_vector/</a></li>
  <li>
    <p>slides: <a href="http://www.esat.kuleuven.be/sista/ROKS2013/files/presentations/DSVM_ROKS_2013_WIERING.pdf">http://www.esat.kuleuven.be/sista/ROKS2013/files/presentations/DSVM_ROKS_2013_WIERING.pdf</a>
<strong>Trusting SVM for Piecewise Linear CNNs</strong></p>
  </li>
  <li>intro: PL-CNNs</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.02185">https://arxiv.org/abs/1611.02185</a></li>
</ul>

<h2 id="random-forest">Random Forest</h2>

<p><strong>Towards the effectiveness of Deep Convolutional Neural Network based Fast Random Forest Classifier</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.08864">http://arxiv.org/abs/1609.08864</a></li>
</ul>

<p><strong>Deep Forest: Towards An Alternative to Deep Neural Networks</strong></p>

<ul>
  <li>projetc: <a href="http://lamda.nju.edu.cn/code_gcForest.ashx">http://lamda.nju.edu.cn/code_gcForest.ashx</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.08835">https://arxiv.org/abs/1702.08835</a></li>
  <li>github(official): <a href="https://github.com/kingfengji/gcForest">https://github.com/kingfengji/gcForest</a></li>
</ul>

<p><strong>Forward Thinking: Building Deep Random Forests</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.07366">https://arxiv.org/abs/1705.07366</a></li>
  <li>github: <a href="https://github.com/tkchris93/ForwardThinking">https://github.com/tkchris93/ForwardThinking</a></li>
</ul>

<h2 id="others">Others</h2>

<p><strong>Deep Markov Random Field for Image Modeling</strong></p>

<ul>
  <li>intro: ECCV 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.02036">http://arxiv.org/abs/1609.02036</a></li>
  <li>github: <a href="https://github.com/zhirongw/deep-mrf">https://github.com/zhirongw/deep-mrf</a></li>
</ul>

<p><strong>Deep, Dense, and Low-Rank Gaussian Conditional Random Fields</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.09051">https://arxiv.org/abs/1611.09051</a></li>
</ul>

<p><strong>Deep Probabilistic Programming with Edward</strong></p>

<ul>
  <li>intro: Columbia University &amp; Adobe Research &amp; Google</li>
  <li>poster: <a href="http://dustintran.com/papers/TranHoffmanMurphyBrevdoSaurousBlei2016_poster.pdf">http://dustintran.com/papers/TranHoffmanMurphyBrevdoSaurousBlei2016_poster.pdf</a></li>
</ul>

<p><strong>Deep Bayesian Active Learning with Image Data</strong></p>

<ul>
  <li>project page: <a href="http://mlg.eng.cam.ac.uk/yarin/publications.html#Gal2016Active">http://mlg.eng.cam.ac.uk/yarin/publications.html#Gal2016Active</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.02910">https://arxiv.org/abs/1703.02910</a></li>
</ul>

<p><strong>Deep Robust Kalman Filter</strong></p>

<p><a href="https://arxiv.org/abs/1703.02310">https://arxiv.org/abs/1703.02310</a></p>

<h1 id="deep-learning-and-robots">Deep Learning and Robots</h1>

<p><strong>Robot Learning Manipulation Action Plans by “Watching” Unconstrained Videos from the World Wide Web</strong></p>

<ul>
  <li>intro: AAAI 2015</li>
  <li>paper: <a href="http://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf">http://www.umiacs.umd.edu/~yzyang/paper/YouCookMani_CameraReady.pdf</a></li>
  <li>author page: <a href="http://www.umiacs.umd.edu/~yzyang/">http://www.umiacs.umd.edu/~yzyang/</a></li>
</ul>

<p><strong>End-to-End Training of Deep Visuomotor Policies</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1504.00702">http://arxiv.org/abs/1504.00702</a></li>
</ul>

<p><strong>Comment on Open AI’s Efforts to Robot Learning</strong></p>

<ul>
  <li>blog: <a href="https://gridworld.wordpress.com/2016/07/28/comment-on-open-ais-efforts-to-robot-learning/">https://gridworld.wordpress.com/2016/07/28/comment-on-open-ais-efforts-to-robot-learning/</a></li>
</ul>

<p><strong>The Curious Robot: Learning Visual Representations via Physical Interactions</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1604.01360">http://arxiv.org/abs/1604.01360</a></li>
</ul>

<p><strong>How to build a robot that “sees” with $100 and TensorFlow</strong></p>

<p><img src="https://d3ansictanv2wj.cloudfront.net/Figure_5-5b104cf7a53a9c1ee95110b78fb14256.jpg" height="300" alt="" /></p>

<ul>
  <li>blog: <a href="https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow">https://www.oreilly.com/learning/how-to-build-a-robot-that-sees-with-100-and-tensorflow</a></li>
</ul>

<p><strong>Deep Visual Foresight for Planning Robot Motion</strong></p>

<ul>
  <li>project page: <a href="https://sites.google.com/site/brainrobotdata/">https://sites.google.com/site/brainrobotdata/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.00696">https://arxiv.org/abs/1610.00696</a></li>
  <li>video: <a href="https://sites.google.com/site/robotforesight/">https://sites.google.com/site/robotforesight/</a></li>
</ul>

<p><strong>Sim-to-Real Robot Learning from Pixels with Progressive Nets</strong></p>

<ul>
  <li>intro: Google DeepMind</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.04286">https://arxiv.org/abs/1610.04286</a></li>
</ul>

<p><strong>Towards Lifelong Self-Supervision: A Deep Learning Direction for Robotics</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00201">https://arxiv.org/abs/1611.00201</a></li>
</ul>

<p><strong>A Differentiable Physics Engine for Deep Learning in Robotics</strong></p>

<ul>
  <li>paper: <a href="http://openreview.net/pdf?id=SyEiHNKxx">http://openreview.net/pdf?id=SyEiHNKxx</a></li>
</ul>

<p><strong>Deep-learning in Mobile Robotics - from Perception to Control Systems: A Survey on Why and Why not</strong></p>

<ul>
  <li>intro: City University of Hong Kong &amp; Hong Kong University of Science and Technology</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.07139">https://arxiv.org/abs/1612.07139</a></li>
</ul>

<p><strong>Deep Robotic Learning</strong></p>

<ul>
  <li>intro: <a href="https://simons.berkeley.edu/talks/sergey-levine-01-24-2017-1">https://simons.berkeley.edu/talks/sergey-levine-01-24-2017-1</a></li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=jtjW5Pye_44">https://www.youtube.com/watch?v=jtjW5Pye_44</a></li>
</ul>

<p><strong>Deep Learning in Robotics: A Review of Recent Research</strong></p>

<p><a href="https://arxiv.org/abs/1707.07217">https://arxiv.org/abs/1707.07217</a></p>

<h1 id="deep-learning-on-mobile--embedded-devices">Deep Learning on Mobile / Embedded Devices</h1>

<p><strong>Convolutional neural networks on the iPhone with VGGNet</strong></p>

<ul>
  <li>blog: <a href="http://matthijshollemans.com/2016/08/30/vggnet-convolutional-neural-network-iphone/">http://matthijshollemans.com/2016/08/30/vggnet-convolutional-neural-network-iphone/</a></li>
  <li>github: <a href="https://github.com/hollance/VGGNet-Metal">https://github.com/hollance/VGGNet-Metal</a></li>
</ul>

<p><strong>TensorFlow for Mobile Poets</strong></p>

<ul>
  <li>blog: <a href="https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/">https://petewarden.com/2016/09/27/tensorflow-for-mobile-poets/</a></li>
</ul>

<p><strong>The Convolutional Neural Network(CNN) for Android</strong></p>

<ul>
  <li>intro: CnnForAndroid:A Classification Project using Convolutional Neural Network(CNN) in Android platform。It also support Caffe Model</li>
  <li>github: <a href="https://github.com/zhangqianhui/CnnForAndroid">https://github.com/zhangqianhui/CnnForAndroid</a></li>
</ul>

<p><strong>TensorFlow on Android</strong></p>

<ul>
  <li>blog: <a href="https://www.oreilly.com/learning/tensorflow-on-android">https://www.oreilly.com/learning/tensorflow-on-android</a></li>
</ul>

<p><strong>Experimenting with TensorFlow on Android</strong></p>

<ul>
  <li>part 1: <a href="https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-pt-1-362683b31838#.5gbp2d4st">https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-pt-1-362683b31838#.5gbp2d4st</a></li>
  <li>part 2: <a href="https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.2gx3o65f5">https://medium.com/@mgazar/experimenting-with-tensorflow-on-android-part-2-12f3dc294eaf#.2gx3o65f5</a></li>
  <li>github: <a href="https://github.com/MostafaGazar/tensorflow">https://github.com/MostafaGazar/tensorflow</a></li>
</ul>

<p><strong>XNOR.ai frees AI from the prison of the supercomputer</strong></p>

<ul>
  <li>blog: <a href="https://techcrunch.com/2017/01/19/xnor-ai-frees-ai-from-the-prison-of-the-supercomputer/">https://techcrunch.com/2017/01/19/xnor-ai-frees-ai-from-the-prison-of-the-supercomputer/</a></li>
</ul>

<p><strong>Embedded Deep Learning with NVIDIA Jetson</strong></p>

<ul>
  <li>youtube: <a href="https://www.youtube.com/watch?v=_4tzlXPQWb8">https://www.youtube.com/watch?v=_4tzlXPQWb8</a></li>
  <li>mirror: <a href="https://pan.baidu.com/s/1pKCDXkZ">https://pan.baidu.com/s/1pKCDXkZ</a></li>
</ul>

<p><strong>Embedded and mobile deep learning research resources</strong></p>

<p><a href="https://github.com/csarron/emdl">https://github.com/csarron/emdl</a></p>

<h1 id="deep-learning-in-finance">Deep Learning in Finance</h1>

<p><strong>Deep Learning in Finance</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.06561">http://arxiv.org/abs/1602.06561</a></li>
</ul>

<p><strong>A Survey of Deep Learning Techniques Applied to Trading</strong></p>

<ul>
  <li>blog: <a href="http://gregharris.info/a-survey-of-deep-learning-techniques-applied-to-trading/">http://gregharris.info/a-survey-of-deep-learning-techniques-applied-to-trading/</a></li>
</ul>

<p><strong>Deep Learning and Long-Term Investing</strong></p>

<ul>
  <li>part 1: <a href="http://www.euclidean.com/deep-learning-long-term-investing-1">http://www.euclidean.com/deep-learning-long-term-investing-1</a></li>
  <li>part 2: <a href="http://www.euclidean.com/deep-learning-investing-part-2-preprocessing-data">http://www.euclidean.com/deep-learning-investing-part-2-preprocessing-data</a></li>
</ul>

<p><strong>Deep Learning in Trading</strong></p>

<ul>
  <li>youtube: <a href="https://www.youtube.com/watch?v=FoQKCeDuPiY">https://www.youtube.com/watch?v=FoQKCeDuPiY</a></li>
  <li>mirror: <a href="https://pan.baidu.com/s/1sltRra9">https://pan.baidu.com/s/1sltRra9</a></li>
</ul>

<p><strong>Research to Products: Machine &amp; Human Intelligence in Finance</strong></p>

<ul>
  <li>intro: Peter Sarlin, Hanken School of Economics - Deep Learning in Finance Summit 2016 #reworkfin</li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=Fd7Cc-KOVXg">https://www.youtube.com/watch?v=Fd7Cc-KOVXg</a></li>
  <li>mirror: <a href="https://pan.baidu.com/s/1kVpZKur#list/path=%2F">https://pan.baidu.com/s/1kVpZKur#list/path=%2F</a></li>
</ul>

<p><strong>eep Neural Networks for Real-time Market Predictions</strong></p>

<ul>
  <li>youtube: <a href="https://www.youtube.com/watch?v=Kzz2-wAEK7A">https://www.youtube.com/watch?v=Kzz2-wAEK7A</a></li>
</ul>

<p><strong>Deep Learning the Stock Market</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/@TalPerry/deep-learning-the-stock-market-df853d139e02#.z752rf43u">https://medium.com/@TalPerry/deep-learning-the-stock-market-df853d139e02#.z752rf43u</a></li>
  <li>github: <a href="https://github.com/talolard/MarketVectors">https://github.com/talolard/MarketVectors</a></li>
</ul>

<p><strong>rl_portfolio</strong></p>

<ul>
  <li>intro: This Repository uses Reinforcement Learning and Supervised learning to Optimize portfolio allocation.</li>
  <li>github: <a href="https://github.com/deependersingla/deep_portfolio">https://github.com/deependersingla/deep_portfolio</a></li>
</ul>

<p><strong>Neural networks for algorithmic trading. Multivariate time series</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/@alexrachnog/neural-networks-for-algorithmic-trading-2-1-multivariate-time-series-ab016ce70f57">https://medium.com/@alexrachnog/neural-networks-for-algorithmic-trading-2-1-multivariate-time-series-ab016ce70f57</a></li>
  <li>github: <a href="https://github.com/Rachnog/Deep-Trading/tree/master/multivariate">https://github.com/Rachnog/Deep-Trading/tree/master/multivariate</a></li>
</ul>

<p><strong>Deep-Trading: Algorithmic trading with deep learning experiments</strong></p>

<p><a href="https://github.com/Rachnog/Deep-Trading">https://github.com/Rachnog/Deep-Trading</a></p>

<p><strong>Neural networks for algorithmic trading. Multimodal and multitask deep learning</strong></p>

<ul>
  <li>blog: <a href="https://becominghuman.ai/neural-networks-for-algorithmic-trading-multimodal-and-multitask-deep-learning-5498e0098caf">https://becominghuman.ai/neural-networks-for-algorithmic-trading-multimodal-and-multitask-deep-learning-5498e0098caf</a></li>
  <li>github: <a href="https://github.com/Rachnog/Deep-Trading/tree/master/multimodal">https://github.com/Rachnog/Deep-Trading/tree/master/multimodal</a></li>
</ul>

<p><strong>Deep Learning with Python in Finance - Singapore Python User Group</strong></p>

<ul>
  <li>youtube: <a href="https://www.youtube.com/watch?v=xvm-M-R2fZY">https://www.youtube.com/watch?v=xvm-M-R2fZY</a></li>
</ul>

<p><strong>A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem</strong></p>

<ul>
  <li>intro: Xi’an Jiaotong-Liverpool University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.10059">https://arxiv.org/abs/1706.10059</a></li>
</ul>

<p><strong>Stock Prediction: a method based on extraction of news features and recurrent neural networks</strong></p>

<ul>
  <li>intro: Peking University. The 22nd China Conference on Information Retrieval</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.07585">https://arxiv.org/abs/1707.07585</a></li>
</ul>

<p><strong>Multidimensional LSTM Networks to Predict Bitcoin Price</strong></p>

<ul>
  <li>blog: <a href="http://www.jakob-aungiers.com/articles/a/Multidimensional-LSTM-Networks-to-Predict-Bitcoin-Price">http://www.jakob-aungiers.com/articles/a/Multidimensional-LSTM-Networks-to-Predict-Bitcoin-Price</a></li>
  <li>github: <a href="https://github.com/jaungiers/Multidimensional-LSTM-BitCoin-Time-Series">https://github.com/jaungiers/Multidimensional-LSTM-BitCoin-Time-Series</a></li>
</ul>

<h1 id="deep-learning-in-speech">Deep Learning in Speech</h1>

<p><strong>Deep Speech 2: End-to-End Speech Recognition in English and Mandarin</strong></p>

<ul>
  <li>intro: Baidu Research, ICML 2016</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1512.02595">https://arxiv.org/abs/1512.02595</a></li>
  <li>github(Neon): <a href="https://github.com/NervanaSystems/deepspeech">https://github.com/NervanaSystems/deepspeech</a></li>
</ul>

<p><strong>End-to-end speech recognition with neon</strong></p>

<ul>
  <li>blog: <a href="https://www.nervanasys.com/end-end-speech-recognition-neon/">https://www.nervanasys.com/end-end-speech-recognition-neon/</a></li>
</ul>

<h2 id="wavenet">WaveNet</h2>

<p><strong>WaveNet: A Generative Model for Raw Audio</strong></p>

<ul>
  <li>homepage: <a href="https://deepmind.com/blog/wavenet-generative-model-raw-audio/">https://deepmind.com/blog/wavenet-generative-model-raw-audio/</a></li>
  <li>paper: <a href="https://drive.google.com/file/d/0B3cxcnOkPx9AeWpLVXhkTDJINDQ/view">https://drive.google.com/file/d/0B3cxcnOkPx9AeWpLVXhkTDJINDQ/view</a></li>
  <li>mirror: <a href="https://pan.baidu.com/s/1gfmGWaJ">https://pan.baidu.com/s/1gfmGWaJ</a></li>
  <li>github: <a href="https://github.com/usernaamee/keras-wavenet">https://github.com/usernaamee/keras-wavenet</a></li>
  <li>github: <a href="https://github.com/ibab/tensorflow-wavenet">https://github.com/ibab/tensorflow-wavenet</a></li>
  <li>github: <a href="https://github.com/monthly-hack/chainer-wavenet">https://github.com/monthly-hack/chainer-wavenet</a></li>
  <li>github: <a href="https://github.com/huyouare/WaveNet-Theano">https://github.com/huyouare/WaveNet-Theano</a></li>
  <li>github(Keras): <a href="https://github.com/basveeling/wavenet">https://github.com/basveeling/wavenet</a></li>
  <li>github: <a href="https://github.com/ritheshkumar95/WaveNet">https://github.com/ritheshkumar95/WaveNet</a></li>
</ul>

<p><strong>A TensorFlow implementation of DeepMind’s WaveNet paper for text generation.</strong></p>

<ul>
  <li>github: <a href="https://github.com/Zeta36/tensorflow-tex-wavenet">https://github.com/Zeta36/tensorflow-tex-wavenet</a></li>
</ul>

<p><strong>Fast Wavenet Generation Algorithm</strong></p>

<ul>
  <li>intro: An efficient Wavenet generation implementation</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.09482">https://arxiv.org/abs/1611.09482</a></li>
  <li>github <a href="https://github.com/tomlepaine/fast-wavenet">https://github.com/tomlepaine/fast-wavenet</a></li>
</ul>

<p><strong>Speech-to-Text-WaveNet : End-to-end sentence level English speech recognition based on DeepMind’s WaveNet and tensorflow</strong></p>

<ul>
  <li>github: <a href="https://github.com/buriburisuri/speech-to-text-wavenet">https://github.com/buriburisuri/speech-to-text-wavenet</a></li>
</ul>

<p><strong>Wav2Letter: an End-to-End ConvNet-based Speech Recognition System</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.03193">http://arxiv.org/abs/1609.03193</a></li>
</ul>

<p><strong>TristouNet: Triplet Loss for Speaker Turn Embedding</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1609.04301">https://arxiv.org/abs/1609.04301</a></li>
  <li>github: <a href="https://github.com/hbredin/TristouNet">https://github.com/hbredin/TristouNet</a></li>
</ul>

<p><strong>Speech Recognion and Deep Learning</strong></p>

<ul>
  <li>intro: Baidu Research Silicon Valley AI Lab</li>
  <li>slides: <a href="http://cs.stanford.edu/~acoates/ba_dls_speech2016.pdf">http://cs.stanford.edu/~acoates/ba_dls_speech2016.pdf</a></li>
  <li>mirror: <a href="https://pan.baidu.com/s/1qYrPkPQ">https://pan.baidu.com/s/1qYrPkPQ</a></li>
  <li>github: <a href="https://github.com/baidu-research/ba-dls-deepspeech">https://github.com/baidu-research/ba-dls-deepspeech</a></li>
</ul>

<p><strong>Robust end-to-end deep audiovisual speech recognition</strong></p>

<ul>
  <li>intro: CMU</li>
  <li>github: <a href="https://arxiv.org/abs/1611.06986">https://arxiv.org/abs/1611.06986</a></li>
</ul>

<p><strong>An Experimental Comparison of Deep Neural Networks for End-to-end Speech Recognition</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.07174">https://arxiv.org/abs/1611.07174</a></li>
</ul>

<p><strong>Recurrent Deep Stacking Networks for Speech Recognition</strong></p>

<ul>
  <li>intro: The Ohio State University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.04675">https://arxiv.org/abs/1612.04675</a></li>
</ul>

<p><strong>Towards End-to-End Speech Recognition with Deep Convolutional Neural Networks</strong></p>

<ul>
  <li>intro: Universite de Montreal &amp; CIFAR</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.02720">https://arxiv.org/abs/1701.02720</a></li>
</ul>

<h1 id="deep-learning-for-sound--music">Deep Learning for Sound / Music</h1>

<h2 id="sound">Sound</h2>

<p><strong>Suggesting Sounds for Images from Video Collections</strong></p>

<ul>
  <li>intro: ETH Zurich &amp; 2Disney Research</li>
  <li>paper: <a href="https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20161014182443/Suggesting-Sounds-for-Images-from-Video-Collections-Paper.pdf">https://s3-us-west-1.amazonaws.com/disneyresearch/wp-content/uploads/20161014182443/Suggesting-Sounds-for-Images-from-Video-Collections-Paper.pdf</a></li>
</ul>

<p><strong>Disney AI System Associates Images with Sounds</strong></p>

<ul>
  <li>blog: <a href="https://news.developer.nvidia.com/disneys-ai-system-associates-images-with-sounds/">https://news.developer.nvidia.com/disneys-ai-system-associates-images-with-sounds/</a></li>
</ul>

<p><strong>Convolutional Recurrent Neural Networks for Bird Audio Detection</strong></p>

<p><a href="https://arxiv.org/abs/1703.02317">https://arxiv.org/abs/1703.02317</a></p>

<h2 id="music">Music</h2>

<p><strong>Learning Features of Music from Scratch</strong></p>

<ul>
  <li>intro: University of Washington. MusicNet</li>
  <li>project page: <a href="http://homes.cs.washington.edu/~thickstn/musicnet.html">http://homes.cs.washington.edu/~thickstn/musicnet.html</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.09827">https://arxiv.org/abs/1611.09827</a></li>
  <li>demo: <a href="http://homes.cs.washington.edu/~thickstn/demos.html">http://homes.cs.washington.edu/~thickstn/demos.html</a></li>
</ul>

<p><strong>DeepBach: a Steerable Model for Bach chorales generation</strong></p>

<ul>
  <li>project page: <a href="http://www.flow-machines.com/deepbach-steerable-model-bach-chorales-generation/">http://www.flow-machines.com/deepbach-steerable-model-bach-chorales-generation/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01010">https://arxiv.org/abs/1612.01010</a></li>
  <li>github: <a href="https://github.com/SonyCSL-Paris/DeepBach">https://github.com/SonyCSL-Paris/DeepBach</a></li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=QiBM7-5hA6o">https://www.youtube.com/watch?v=QiBM7-5hA6o</a></li>
</ul>

<p><strong>Deep Learning for Music</strong></p>

<ul>
  <li>blog: <a href="https://amundtveit.com/2016/11/22/deep-learning-for-music/">https://amundtveit.com/2016/11/22/deep-learning-for-music/</a></li>
</ul>

<p><strong>First International Workshop on Deep Learning and Music</strong></p>

<p><a href="https://arxiv.org/html/1706.08675">https://arxiv.org/html/1706.08675</a></p>

<h1 id="deep-learning-on-games">Deep Learning on Games</h1>

<p><strong>TorchCraft: a Library for Machine Learning Research on Real-Time Strategy Games</strong></p>

<ul>
  <li>intro: Connecting Torch to StarCraft</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00625">https://arxiv.org/abs/1611.00625</a></li>
  <li>github: <a href="https://github.com/TorchCraft/TorchCraft">https://github.com/TorchCraft/TorchCraft</a></li>
</ul>

<p><strong>BlizzCon 2016 DeepMind and StarCraft II Deep Learning Panel Transcript</strong></p>

<ul>
  <li>part 1: <a href="http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript">http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript</a></li>
  <li>part 2: <a href="http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript/2">http://starcraft.blizzplanet.com/blog/comments/blizzcon-2016-deepmind-and-starcraft-ii-deep-learning-panel-transcript/2</a></li>
</ul>

<p><strong>DeepStack: Expert-Level Artificial Intelligence in No-Limit Poker</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.01724">https://arxiv.org/abs/1701.01724</a></li>
  <li>github: <a href="https://github.com/lifrordi/DeepStack-Leduc">https://github.com/lifrordi/DeepStack-Leduc</a></li>
</ul>

<p><strong>Gym StarCraft: StarCraft environment for OpenAI Gym, based on Facebook’s TorchCraft</strong></p>

<ul>
  <li>intro: Gym StarCraft is an environment bundle for OpenAI Gym. 
It is based on Facebook’s TorchCraft, which is a bridge between Torch and StarCraft for AI research.</li>
  <li>github: <a href="https://github.com/deepcraft/gym-starcraft">https://github.com/deepcraft/gym-starcraft</a></li>
</ul>

<p><strong>Multiagent Bidirectionally-Coordinated Nets for Learning to Play StarCraft Combat Games</strong></p>

<p><a href="https://arxiv.org/abs/1703.10069">https://arxiv.org/abs/1703.10069</a></p>

<p><strong>Learning Macromanagement in StarCraft from Replays using Deep Learning</strong></p>

<ul>
  <li>intro: CIG 2017. IT University of Copenhagen</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.03743">https://arxiv.org/abs/1707.03743</a></li>
</ul>

<h1 id="deep-learning-in-medicine-and-biology">Deep Learning in Medicine and Biology</h1>

<p><strong>Low Data Drug Discovery with One-shot Learning</strong></p>

<ul>
  <li>intro: MIT &amp; Stanford University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.03199">https://arxiv.org/abs/1611.03199</a></li>
  <li>homepage: <a href="http://deepchem.io/">http://deepchem.io/</a></li>
  <li>github: <a href="https://github.com/deepchem/deepchem">https://github.com/deepchem/deepchem</a></li>
</ul>

<p><strong>Democratizing Drug Discovery with DeepChem</strong></p>

<ul>
  <li>youtube: <a href="https://www.youtube.com/watch?v=sntikyFI8s8">https://www.youtube.com/watch?v=sntikyFI8s8</a></li>
</ul>

<p><strong>Introduction to Deep Learning in Medicine and Biology</strong></p>

<ul>
  <li>blog: <a href="http://a12d.com/deep-learning-biomedicine">http://a12d.com/deep-learning-biomedicine</a></li>
</ul>

<p><strong>Deep Learning for Alzheimer Diagnostics and Decision Support</strong></p>

<p><a href="https://amundtveit.com/2016/11/18/deep-learning-for-alzheimer-diagnostics-and-decision-support/">https://amundtveit.com/2016/11/18/deep-learning-for-alzheimer-diagnostics-and-decision-support/</a></p>

<p><strong>DeepCancer: Detecting Cancer through Gene Expressions via Deep Generative Learning</strong></p>

<ul>
  <li>intro: University of Florida</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.03211">https://arxiv.org/abs/1612.03211</a></li>
</ul>

<p><strong>Towards biologically plausible deep learning</strong></p>

<ul>
  <li>intro: Yoshua	Bengio, NIPS’2016 Workshops</li>
  <li>slides: <a href="http://www.iro.umontreal.ca/~bengioy/talks/Brains+Bits-NIPS2016Workshop.pptx.pdf">http://www.iro.umontreal.ca/~bengioy/talks/Brains+Bits-NIPS2016Workshop.pptx.pdf</a></li>
</ul>

<p><strong>Deep Learning and Its Applications to Machine Health Monitoring: A Survey</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.07640">https://arxiv.org/abs/1612.07640</a></li>
</ul>

<p><strong>Generating Focussed Molecule Libraries for Drug Discovery with Recurrent Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.01329">https://arxiv.org/abs/1701.01329</a></li>
</ul>

<p><strong>Deep Learning Applications in Medical Imaging</strong></p>

<ul>
  <li>blog: <a href="http://techemergence.com/deep-learning-medical-applications/">http://techemergence.com/deep-learning-medical-applications/</a></li>
</ul>

<p><strong>Dermatologist-level classification of skin cancer with deep neural networks</strong></p>

<ul>
  <li>intro: Stanford University. Nature 2017</li>
  <li>paper: <a href="http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature21056.pdf">http://www.nature.com/nature/journal/vaop/ncurrent/pdf/nature21056.pdf</a></li>
</ul>

<p><strong>Deep Learning for Health Informatics</strong></p>

<ul>
  <li>intro: Imperial College London</li>
  <li>paper: <a href="http://ieeexplore.ieee.org/abstract/document/7801947/">http://ieeexplore.ieee.org/abstract/document/7801947/</a></li>
</ul>

<h1 id="deep-learning-for-fashion">Deep Learning for Fashion</h1>

<p><strong>Convolutional Neural Networks for Fashion Classification and Object Detection</strong></p>

<ul>
  <li>intro: CS231N project</li>
  <li>paper: <a href="http://cs231n.stanford.edu/reports/BLAO_KJAG_CS231N_FinalPaperFashionClassification.pdf">http://cs231n.stanford.edu/reports/BLAO_KJAG_CS231N_FinalPaperFashionClassification.pdf</a></li>
</ul>

<p><strong>DeepFashion: Powering Robust Clothes Recognition and Retrieval with Rich Annotations</strong></p>

<ul>
  <li>intro: CVPR 2016</li>
  <li>project page: <a href="http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html">http://personal.ie.cuhk.edu.hk/~lz013/projects/DeepFashion.html</a></li>
  <li>paper: <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf">http://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Liu_DeepFashion_Powering_Robust_CVPR_2016_paper.pdf</a></li>
</ul>

<p><strong>Deep Learning for Fast and Accurate Fashion Item Detection</strong></p>

<ul>
  <li>keywords:  MultiBox and Fast R-CNN, Kuznech-Fashion-156 and Kuznech-Fashion-205 fashion item detection datasets</li>
  <li>paper: <a href="https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf">https://kddfashion2016.mybluemix.net/kddfashion_finalSubmissions/Deep%20Learning%20for%20Fast%20and%20Accurate%20Fashion%20Item%20Detection.pdf</a></li>
</ul>

<p><strong>Deep Learning at GILT</strong></p>

<ul>
  <li>keywords: automated tagging, automatic dress faceting</li>
  <li>blog: <a href="http://tech.gilt.com/machine/learning,/deep/learning/2016/12/22/deep-learning-at-gilt">http://tech.gilt.com/machine/learning,/deep/learning/2016/12/22/deep-learning-at-gilt</a></li>
</ul>

<p><strong>Working with Fashion Models</strong></p>

<ul>
  <li>blog: <a href="https://making.lyst.com/2017/02/21/working-with-fashion-models/">https://making.lyst.com/2017/02/21/working-with-fashion-models/</a></li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=emr2qaCQOQs">https://www.youtube.com/watch?v=emr2qaCQOQs</a></li>
</ul>

<p><strong>Fashion Forward: Forecasting Visual Style in Fashion</strong></p>

<ul>
  <li>intro: Karlsruhe Institute of Technology &amp; The University of Texas at Austin</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.06394">https://arxiv.org/abs/1705.06394</a></li>
</ul>

<p><strong>StreetStyle: Exploring world-wide clothing styles from millions of photos</strong></p>

<ul>
  <li>homepage: <a href="http://streetstyle.cs.cornell.edu/">http://streetstyle.cs.cornell.edu/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.01869">https://arxiv.org/abs/1706.01869</a></li>
  <li>demo: <a href="http://streetstyle.cs.cornell.edu/trends.html">http://streetstyle.cs.cornell.edu/trends.html</a></li>
</ul>

<p><strong>Fashioning with Networks: Neural Style Transfer to Design Clothes</strong></p>

<ul>
  <li>intro: ML4Fashion 2017</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.09899">https://arxiv.org/abs/1707.09899</a></li>
</ul>

<p><strong>Deep Learning Our Way Through Fashion Week</strong></p>

<p><a href="https://inside.edited.com/deep-learning-our-way-through-fashion-week-ea55bf50bab8">https://inside.edited.com/deep-learning-our-way-through-fashion-week-ea55bf50bab8</a></p>

<h1 id="benchmarks">Benchmarks</h1>

<p><strong>Deep Learning’s Accuracy</strong></p>

<ul>
  <li>blog: <a href="http://deeplearning4j.org/accuracy.html">http://deeplearning4j.org/accuracy.html</a></li>
</ul>

<p><strong>Benchmarks for popular CNN models</strong></p>

<ul>
  <li>intro: Benchmarks for popular convolutional neural network models on CPU and different GPUs, with and without cuDNN.</li>
  <li>github: <a href="https://github.com/jcjohnson/cnn-benchmarks">https://github.com/jcjohnson/cnn-benchmarks</a></li>
</ul>

<p><strong>Deep Learning Benchmarks</strong></p>

<p><a href="http://add-for.com/deep-learning-benchmarks/">http://add-for.com/deep-learning-benchmarks/</a></p>

<p><strong>cudnn-rnn-benchmarks</strong></p>

<ul>
  <li>github: <a href="https://github.com/MaximumEntropy/cudnn_rnn_theano_benchmarks">https://github.com/MaximumEntropy/cudnn_rnn_theano_benchmarks</a></li>
</ul>

<h1 id="papers">Papers</h1>

<p><strong>Reweighted Wake-Sleep</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1406.2751">http://arxiv.org/abs/1406.2751</a></li>
  <li>github: <a href="https://github.com/jbornschein/reweighted-ws">https://github.com/jbornschein/reweighted-ws</a></li>
</ul>

<p><strong>Probabilistic Backpropagation for Scalable Learning of Bayesian Neural Networks</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1502.05336">http://arxiv.org/abs/1502.05336</a></li>
  <li>github: <a href="https://github.com/HIPS/Probabilistic-Backpropagation">https://github.com/HIPS/Probabilistic-Backpropagation</a></li>
</ul>

<p><strong>Deeply-Supervised Nets</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1409.5185">http://arxiv.org/abs/1409.5185</a></li>
  <li>github: <a href="https://github.com/mbhenaff/spectral-lib">https://github.com/mbhenaff/spectral-lib</a></li>
</ul>

<p><strong>Deep learning</strong></p>

<ul>
  <li>intro: Nature 2015</li>
  <li>author: Yann LeCun, Yoshua Bengio &amp; Geoffrey Hinton</li>
  <li>paper: <a href="http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf">http://www.cs.toronto.edu/~hinton/absps/NatureDeepReview.pdf</a></li>
</ul>

<p><strong>On the Expressive Power of Deep Learning: A Tensor Analysis</strong></p>

<ul>
  <li>paper: <a href="http://arxiv.org/abs/1509.05009">http://arxiv.org/abs/1509.05009</a></li>
</ul>

<p><strong>Understanding and Predicting Image Memorability at a Large Scale</strong></p>

<ul>
  <li>intro: MIT. ICCV 2015</li>
  <li>homepage: <a href="http://memorability.csail.mit.edu/">http://memorability.csail.mit.edu/</a></li>
  <li>paper: <a href="https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf">https://people.csail.mit.edu/khosla/papers/iccv2015_khosla.pdf</a></li>
  <li>code: <a href="http://memorability.csail.mit.edu/download.html">http://memorability.csail.mit.edu/download.html</a></li>
  <li>reviews: <a href="http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/">http://petapixel.com/2015/12/18/how-memorable-are-times-top-10-photos-of-2015-to-a-computer/</a></li>
</ul>

<p><strong>A Survey: Time Travel in Deep Learning Space: An Introduction to Deep Learning Models and How Deep Learning Models Evolved from the Initial Ideas</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1510.04781">http://arxiv.org/abs/1510.04781</a></li>
</ul>

<p><strong>Towards Open Set Deep Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.06233">http://arxiv.org/abs/1511.06233</a></li>
  <li>github: <a href="https://github.com/abhijitbendale/OSDN">https://github.com/abhijitbendale/OSDN</a></li>
</ul>

<p><strong>Structured Prediction Energy Networks</strong></p>

<ul>
  <li>intro: ICML 2016. SPEN</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.06350">http://arxiv.org/abs/1511.06350</a></li>
  <li>github: <a href="https://github.com/davidBelanger/SPEN">https://github.com/davidBelanger/SPEN</a></li>
</ul>

<p><strong>A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.06293">http://arxiv.org/abs/1512.06293</a></li>
</ul>

<p><strong>Deep Neural Networks predict Hierarchical Spatio-temporal Cortical Dynamics of Human Visual Object Recognition</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.02970">http://arxiv.org/abs/1601.02970</a></li>
  <li>demo: <a href="http://brainmodels.csail.mit.edu/dnn/drawCNN/">http://brainmodels.csail.mit.edu/dnn/drawCNN/</a></li>
</ul>

<p><strong>A Mathematical Theory of Deep Convolutional Neural Networks for Feature Extraction</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.06293">http://arxiv.org/abs/1512.06293</a></li>
</ul>

<p><strong>Recent Advances in Convolutional Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.07108">http://arxiv.org/abs/1512.07108</a></li>
</ul>

<p><strong>Understanding Deep Convolutional Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.04920">http://arxiv.org/abs/1601.04920</a></li>
</ul>

<p><strong>DeepCare: A Deep Dynamic Memory Model for Predictive Medicine</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.00357">http://arxiv.org/abs/1602.00357</a></li>
</ul>

<p><strong>Exploiting Cyclic Symmetry in Convolutional Neural Networks</strong></p>

<p><img src="http://benanne.github.io/images/cyclicroll.png" height="300" alt="" /></p>

<ul>
  <li>intro: ICML 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.02660">http://arxiv.org/abs/1602.02660</a></li>
  <li>github(Winning solution for the National Data Science Bowl competition on Kaggle (plankton classification)): <a href="https://github.com/benanne/kaggle-ndsb">https://github.com/benanne/kaggle-ndsb</a></li>
  <li>ref(use Cyclic pooling): <a href="http://benanne.github.io/2015/03/17/plankton.html">http://benanne.github.io/2015/03/17/plankton.html</a></li>
</ul>

<p><strong>Cross-dimensional Weighting for Aggregated Deep Convolutional Features</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1512.04065">http://arxiv.org/abs/1512.04065</a></li>
  <li>github: <a href="https://github.com/yahoo/crow">https://github.com/yahoo/crow</a></li>
</ul>

<p><strong>Understanding Visual Concepts with Continuation Learning</strong></p>

<ul>
  <li>project page: <a href="http://willwhitney.github.io/understanding-visual-concepts/">http://willwhitney.github.io/understanding-visual-concepts/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.06822">http://arxiv.org/abs/1602.06822</a></li>
  <li>github: <a href="https://github.com/willwhitney/understanding-visual-concepts">https://github.com/willwhitney/understanding-visual-concepts</a></li>
</ul>

<p><strong>Learning Efficient Algorithms with Hierarchical Attentive Memory</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.03218">http://arxiv.org/abs/1602.03218</a></li>
  <li>github: <a href="https://github.com/Smerity/tf-ham">https://github.com/Smerity/tf-ham</a></li>
</ul>

<p><strong>DrMAD: Distilling Reverse-Mode Automatic Differentiation for Optimizing Hyperparameters of Deep Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.00917">http://arxiv.org/abs/1601.00917</a></li>
  <li>github: <a href="https://github.com/bigaidream-projects/drmad">https://github.com/bigaidream-projects/drmad</a></li>
</ul>

<p><strong>Do Deep Convolutional Nets Really Need to be Deep (Or Even Convolutional)?</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.05691">http://arxiv.org/abs/1603.05691</a></li>
  <li>review: <a href="http://www.erogol.com/paper-review-deep-convolutional-nets-really-need-deep-even-convolutional/">http://www.erogol.com/paper-review-deep-convolutional-nets-really-need-deep-even-convolutional/</a></li>
</ul>

<p><strong>Harnessing Deep Neural Networks with Logic Rules</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.06318">http://arxiv.org/abs/1603.06318</a></li>
</ul>

<p><strong>Degrees of Freedom in Deep Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.09260">http://arxiv.org/abs/1603.09260</a></li>
</ul>

<p><strong>Deep Networks with Stochastic Depth</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.09382">http://arxiv.org/abs/1603.09382</a></li>
  <li>github: <a href="https://github.com/yueatsprograms/Stochastic_Depth">https://github.com/yueatsprograms/Stochastic_Depth</a></li>
  <li>notes(“Stochastic Depth Networks will Become the New Normal”): <a href="http://deliprao.com/archives/134">http://deliprao.com/archives/134</a></li>
  <li>github: <a href="https://github.com/dblN/stochastic_depth_keras">https://github.com/dblN/stochastic_depth_keras</a></li>
  <li>github: <a href="https://github.com/yasunorikudo/chainer-ResDrop">https://github.com/yasunorikudo/chainer-ResDrop</a></li>
  <li>review: <a href="https://medium.com/@tim_nth/review-deep-networks-with-stochastic-depth-51bd53acfe72">https://medium.com/@tim_nth/review-deep-networks-with-stochastic-depth-51bd53acfe72</a></li>
</ul>

<p><strong>LIFT: Learned Invariant Feature Transform</strong></p>

<ul>
  <li>intro: ECCV 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.09114">http://arxiv.org/abs/1603.09114</a></li>
  <li>github(official): <a href="https://github.com/cvlab-epfl/LIFT">https://github.com/cvlab-epfl/LIFT</a></li>
</ul>

<p><strong>Bridging the Gaps Between Residual Learning, Recurrent Neural Networks and Visual Cortex</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1604.03640">https://arxiv.org/abs/1604.03640</a></li>
  <li>slides: <a href="http://prlab.tudelft.nl/sites/default/files/rnnResnetCortex.pdf">http://prlab.tudelft.nl/sites/default/files/rnnResnetCortex.pdf</a></li>
</ul>

<p><strong>Understanding How Image Quality Affects Deep Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1604.04004">http://arxiv.org/abs/1604.04004</a></li>
  <li>reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/4exk3u/dcnns_are_more_sensitive_to_blur_and_noise_than/">https://www.reddit.com/r/MachineLearning/comments/4exk3u/dcnns_are_more_sensitive_to_blur_and_noise_than/</a></li>
</ul>

<p><strong>Deep Embedding for Spatial Role Labeling</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1603.08474">http://arxiv.org/abs/1603.08474</a></li>
  <li>github: <a href="https://github.com/oswaldoludwig/visually-informed-embedding-of-word-VIEW-">https://github.com/oswaldoludwig/visually-informed-embedding-of-word-VIEW-</a></li>
</ul>

<p><strong>Unreasonable Effectiveness of Learning Neural Nets: Accessible States and Robust Ensembles</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1605.06444">http://arxiv.org/abs/1605.06444</a></li>
</ul>

<p><strong>Learning Deep Representation for Imbalanced Classification</strong></p>

<p><img src="http://mmlab.ie.cuhk.edu.hk/projects/LMLE/method.png" height="300" alt="" /></p>

<ul>
  <li>intro: CVPR 2016</li>
  <li>keywords: Deep Learning Large Margin Local Embedding (LMLE)</li>
  <li>project page: <a href="http://mmlab.ie.cuhk.edu.hk/projects/LMLE.html">http://mmlab.ie.cuhk.edu.hk/projects/LMLE.html</a></li>
  <li>paper: <a href="http://personal.ie.cuhk.edu.hk/~ccloy/files/cvpr_2016_imbalanced.pdf">http://personal.ie.cuhk.edu.hk/~ccloy/files/cvpr_2016_imbalanced.pdf</a></li>
  <li>code: <a href="http://mmlab.ie.cuhk.edu.hk/projects/LMLE/lmle_code.zip">http://mmlab.ie.cuhk.edu.hk/projects/LMLE/lmle_code.zip</a></li>
</ul>

<p><strong>Newtonian Image Understanding: Unfolding the Dynamics of Objects in Static Images</strong></p>

<p><img src="http://allenai.org/images/projects/plato_newton.png?cb=1466683222538" height="300" alt="" /></p>

<ul>
  <li>homepage: <a href="http://allenai.org/plato/newtonian-understanding/">http://allenai.org/plato/newtonian-understanding/</a></li>
  <li>arxiv: <a href="http://arxiv.org/abs/1511.04048">http://arxiv.org/abs/1511.04048</a></li>
  <li>github: <a href="https://github.com/roozbehm/newtonian">https://github.com/roozbehm/newtonian</a></li>
</ul>

<p><strong>DeepMath - Deep Sequence Models for Premise Selection</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1606.04442">https://arxiv.org/abs/1606.04442</a></li>
  <li>github: <a href="https://github.com/tensorflow/deepmath">https://github.com/tensorflow/deepmath</a></li>
</ul>

<p><strong>Convolutional Neural Networks Analyzed via Convolutional Sparse Coding</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1607.08194">http://arxiv.org/abs/1607.08194</a></li>
</ul>

<p><strong>Systematic evaluation of CNN advances on the ImageNet</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1606.02228">http://arxiv.org/abs/1606.02228</a></li>
  <li>github: <a href="https://github.com/ducha-aiki/caffenet-benchmark">https://github.com/ducha-aiki/caffenet-benchmark</a></li>
</ul>

<p><strong>Why does deep and cheap learning work so well?</strong></p>

<ul>
  <li>intro: Harvard and MIT</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.08225">http://arxiv.org/abs/1608.08225</a></li>
  <li>review: <a href="https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/">https://www.technologyreview.com/s/602344/the-extraordinary-link-between-deep-neural-networks-and-the-nature-of-the-universe/</a></li>
</ul>

<p><strong>A scalable convolutional neural network for task-specified scenarios via knowledge distillation</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.05695">http://arxiv.org/abs/1609.05695</a></li>
</ul>

<p><strong>Alternating Back-Propagation for Generator Network</strong></p>

<ul>
  <li>project page(code+data): <a href="http://www.stat.ucla.edu/~ywu/ABP/main.html">http://www.stat.ucla.edu/~ywu/ABP/main.html</a></li>
  <li>paper: <a href="http://www.stat.ucla.edu/~ywu/ABP/doc/arXivABP.pdf">http://www.stat.ucla.edu/~ywu/ABP/doc/arXivABP.pdf</a></li>
</ul>

<p><strong>A Novel Representation of Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.01549">https://arxiv.org/abs/1610.01549</a></li>
</ul>

<p><strong>Optimization of Convolutional Neural Network using Microcanonical Annealing Algorithm</strong></p>

<ul>
  <li>intro: IEEE ICACSIS 2016</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.02306">https://arxiv.org/abs/1610.02306</a></li>
</ul>

<p><strong>Uncertainty in Deep Learning</strong></p>

<ul>
  <li>intro: PhD Thesis. Cambridge Machine Learning Group</li>
  <li>blog: <a href="http://mlg.eng.cam.ac.uk/yarin/blog_2248.html">http://mlg.eng.cam.ac.uk/yarin/blog_2248.html</a></li>
  <li>thesis: <a href="http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf">http://mlg.eng.cam.ac.uk/yarin/thesis/thesis.pdf</a></li>
</ul>

<p><strong>Deep Convolutional Neural Network Design Patterns</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00847">https://arxiv.org/abs/1611.00847</a></li>
  <li>github: <a href="https://github.com/iPhysicist/CNNDesignPatterns">https://github.com/iPhysicist/CNNDesignPatterns</a></li>
</ul>

<p><strong>Extensions and Limitations of the Neural GPU</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00736">https://arxiv.org/abs/1611.00736</a></li>
  <li>github: <a href="https://github.com/openai/ecprice-neural-gpu">https://github.com/openai/ecprice-neural-gpu</a></li>
</ul>

<p><strong>Neural Functional Programming</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.01988">https://arxiv.org/abs/1611.01988</a></li>
</ul>

<p><strong>Deep Information Propagation</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.01232">https://arxiv.org/abs/1611.01232</a></li>
</ul>

<p><strong>Compressed Learning: A Deep Neural Network Approach</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.09615">https://arxiv.org/abs/1610.09615</a></li>
</ul>

<p><strong>A backward pass through a CNN using a generative model of its activations</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.02767">https://arxiv.org/abs/1611.02767</a></li>
</ul>

<p><strong>Understanding deep learning requires rethinking generalization</strong></p>

<ul>
  <li>intro: ICLR 2017 best paper. MIT &amp; Google Brain &amp; UC Berkeley &amp; Google DeepMind</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.03530">https://arxiv.org/abs/1611.03530</a></li>
  <li>example code: <a href="https://github.com/pluskid/fitting-random-labels">https://github.com/pluskid/fitting-random-labels</a></li>
  <li>notes: <a href="https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/">https://theneuralperspective.com/2017/01/24/understanding-deep-learning-requires-rethinking-generalization/</a></li>
</ul>

<p><strong>Local minima in training of deep networks</strong></p>

<ul>
  <li>intro: DeepMind</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.06310">https://arxiv.org/abs/1611.06310</a></li>
</ul>

<p><strong>Learning the Number of Neurons in Deep Networks</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.06321">https://arxiv.org/abs/1611.06321</a></li>
</ul>

<p><strong>Survey of Expressivity in Deep Neural Networks</strong></p>

<ul>
  <li>intro: Presented at NIPS 2016 Workshop on Interpretable Machine Learning in Complex Systems</li>
  <li>intro: Google Brain &amp; Cornell University &amp; Stanford University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.08083">https://arxiv.org/abs/1611.08083</a></li>
</ul>

<p><strong>Designing Neural Network Architectures using Reinforcement Learning</strong></p>

<ul>
  <li>intro: MIT</li>
  <li>project page: <a href="https://bowenbaker.github.io/metaqnn/">https://bowenbaker.github.io/metaqnn/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.02167">https://arxiv.org/abs/1611.02167</a></li>
</ul>

<p><strong>Towards Robust Deep Neural Networks with BANG</strong></p>

<ul>
  <li>intro: University of Colorado</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.00138">https://arxiv.org/abs/1612.00138</a></li>
</ul>

<p><strong>Deep Quantization: Encoding Convolutional Activations with Deep Generative Model</strong></p>

<ul>
  <li>intro: University of Science and Technology of China &amp; MSR</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.09502">https://arxiv.org/abs/1611.09502</a></li>
</ul>

<p><strong>A Probabilistic Theory of Deep Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1504.00641">https://arxiv.org/abs/1504.00641</a></li>
</ul>

<p><strong>A Probabilistic Framework for Deep Learning</strong></p>

<ul>
  <li>intro: Rice University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01936">https://arxiv.org/abs/1612.01936</a></li>
</ul>

<p><strong>Paying More Attention to Attention: Improving the Performance of Convolutional Neural Networks via Attention Transfer</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.03928">https://arxiv.org/abs/1612.03928</a></li>
  <li>github(PyTorch): <a href="https://github.com/szagoruyko/attention-transfer">https://github.com/szagoruyko/attention-transfer</a></li>
</ul>

<p><strong>Risk versus Uncertainty in Deep Learning: Bayes, Bootstrap and the Dangers of Dropout</strong></p>

<ul>
  <li>intro: Google Deepmind</li>
  <li>paper: <a href="http://bayesiandeeplearning.org/papers/BDL_4.pdf">http://bayesiandeeplearning.org/papers/BDL_4.pdf</a></li>
</ul>

<p><strong>Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer</strong></p>

<ul>
  <li>intro: Google Brain &amp; Jagiellonian University</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.06538">https://arxiv.org/abs/1701.06538</a></li>
  <li>reddit: <a href="https://www.reddit.com/r/MachineLearning/comments/5pud72/research_outrageously_large_neural_networks_the/">https://www.reddit.com/r/MachineLearning/comments/5pud72/research_outrageously_large_neural_networks_the/</a></li>
</ul>

<p><strong>Deep Network Guided Proof Search</strong></p>

<ul>
  <li>intro: Google Research &amp; University of Innsbruck</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.06972">https://arxiv.org/abs/1701.06972</a></li>
</ul>

<p><strong>Neural Architecture Search with Reinforcement Learning</strong></p>

<ul>
  <li>intro: Google Brain</li>
  <li>paper: <a href="https://openreview.net/pdf?id=r1Ue8Hcxg">https://openreview.net/pdf?id=r1Ue8Hcxg</a></li>
</ul>

<p><strong>PathNet: Evolution Channels Gradient Descent in Super Neural Networks</strong></p>

<ul>
  <li>intro: Google DeepMind &amp; Google Brain</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.08734">https://arxiv.org/abs/1701.08734</a></li>
  <li>notes: <a href="https://medium.com/intuitionmachine/pathnet-a-modular-deep-learning-architecture-for-agi-5302fcf53273#.8f0o6w3en">https://medium.com/intuitionmachine/pathnet-a-modular-deep-learning-architecture-for-agi-5302fcf53273#.8f0o6w3en</a></li>
</ul>

<p><strong>Reluplex: An Efficient SMT Solver for Verifying Deep Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.01135">https://arxiv.org/abs/1702.01135</a></li>
</ul>

<p><strong>The Power of Sparsity in Convolutional Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.06257">https://arxiv.org/abs/1702.06257</a></li>
</ul>

<p><strong>Learning across scales - A multiscale method for Convolution Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.02009">https://arxiv.org/abs/1703.02009</a></li>
</ul>

<p><strong>Stacking-based Deep Neural Network: Deep Analytic Network on Convolutional Spectral Histogram Features</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.01396">https://arxiv.org/abs/1703.01396</a></li>
</ul>

<p><strong>A Compositional Object-Based Approach to Learning Physical Dynamics</strong></p>

<ul>
  <li>intro: ICLR 2017. Neural Physics Engine</li>
  <li>paper: <a href="https://openreview.net/pdf?id=Bkab5dqxe">https://openreview.net/pdf?id=Bkab5dqxe</a></li>
  <li>github: <a href="https://github.com/mbchang/dynamics">https://github.com/mbchang/dynamics</a></li>
</ul>

<p><strong>Genetic CNN</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.01513">https://arxiv.org/abs/1703.01513</a></li>
  <li>github(Tensorflow): <a href="https://github.com/aqibsaeed/Genetic-CNN">https://github.com/aqibsaeed/Genetic-CNN</a></li>
</ul>

<p><strong>Deep Sets</strong></p>

<ul>
  <li>intro: Amazon Web Services &amp; CMU</li>
  <li>keywords: statistic estimation, point cloud classification, set expansion, and image tagging</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.06114">https://arxiv.org/abs/1703.06114</a></li>
</ul>

<p><strong>Multiscale Hierarchical Convolutional Networks</strong></p>

<p><a href="https://arxiv.org/abs/1703.04140">https://arxiv.org/abs/1703.04140</a>
<a href="https://github.com/jhjacobsen/HierarchicalCNN">https://github.com/jhjacobsen/HierarchicalCNN</a></p>

<p><strong>Deep Neural Networks Do Not Recognize Negative Images</strong></p>

<p><a href="https://arxiv.org/abs/1703.06857">https://arxiv.org/abs/1703.06857</a></p>

<p><strong>Failures of Deep Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.07950">https://arxiv.org/abs/1703.07950</a></li>
  <li>github: <a href="https://github.com/shakedshammah/failures_of_DL">https://github.com/shakedshammah/failures_of_DL</a></li>
</ul>

<p><strong>Multi-Scale Dense Convolutional Networks for Efficient Prediction</strong></p>

<ul>
  <li>intro: Cornell University &amp; Tsinghua University &amp; Fudan University &amp; Facebook AI Research</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.09844">https://arxiv.org/abs/1703.09844</a></li>
  <li>github: <a href="https://github.com/gaohuang/MSDNet">https://github.com/gaohuang/MSDNet</a></li>
</ul>

<p><strong>Scaling the Scattering Transform: Deep Hybrid Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.08961">https://arxiv.org/abs/1703.08961</a></li>
  <li>github: <a href="https://github.com/edouardoyallon/scalingscattering">https://github.com/edouardoyallon/scalingscattering</a></li>
  <li>github(CuPy/PyTorch): <a href="https://github.com/edouardoyallon/pyscatwave">https://github.com/edouardoyallon/pyscatwave</a></li>
</ul>

<p><strong>Coordinating Filters for Faster Deep Neural Networks</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.09746">https://arxiv.org/abs/1703.09746</a></li>
  <li>github: <a href="https://github.com/wenwei202/caffe/tree/sfm">https://github.com/wenwei202/caffe/tree/sfm</a></li>
</ul>

<p><strong>Deep Learning is Robust to Massive Label Noise</strong></p>

<p><a href="https://arxiv.org/abs/1705.10694">https://arxiv.org/abs/1705.10694</a></p>

<p><strong>Input Fast-Forwarding for Better Deep Learning</strong></p>

<ul>
  <li>intro: ICIAR 2017</li>
  <li>keywords: Fast-Forward Network (FFNet)</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1705.08479">https://arxiv.org/abs/1705.08479</a></li>
</ul>

<p><strong>Deep Mutual Learning</strong></p>

<p><a href="https://arxiv.org/abs/1706.00384">https://arxiv.org/abs/1706.00384</a></p>

<p><strong>Methods for Interpreting and Understanding Deep Neural Networks</strong></p>

<ul>
  <li>intro: Technische Universit¨at Berlin &amp; Fraunhofer Heinrich Hertz Institute</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1706.07979">https://arxiv.org/abs/1706.07979</a></li>
</ul>

<p><strong>Automated Problem Identification: Regression vs Classification via Evolutionary Deep Networks</strong></p>

<ul>
  <li>intro: University of Cape Town</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.00703">https://arxiv.org/abs/1707.00703</a></li>
</ul>

<p><strong>Revisiting Unreasonable Effectiveness of Data in Deep Learning Era</strong></p>

<ul>
  <li>intro: Google Research &amp; CMU</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.02968">https://arxiv.org/abs/1707.02968</a></li>
  <li>blog: <a href="https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html">https://research.googleblog.com/2017/07/revisiting-unreasonable-effectiveness.html</a></li>
</ul>

<p><strong>Deep Layer Aggregation</strong></p>

<ul>
  <li>intro: UC Berkeley</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.06484">https://arxiv.org/abs/1707.06484</a></li>
</ul>

<p><strong>Improving Robustness of Feature Representations to Image Deformations using Powered Convolution in CNNs</strong></p>

<p><a href="https://arxiv.org/abs/1707.07830">https://arxiv.org/abs/1707.07830</a></p>

<p><strong>Learning uncertainty in regression tasks by deep neural networks</strong></p>

<ul>
  <li>intro: Free University of Berlin</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.07287">https://arxiv.org/abs/1707.07287</a></li>
</ul>

<p><strong>DenseReg: Fully Convolutional Dense Shape Regression In-the-Wild</strong></p>

<ul>
  <li>intro: CVPR 2017</li>
  <li>project page: <a href="http://alpguler.com/DenseReg.html">http://alpguler.com/DenseReg.html</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01202">https://arxiv.org/abs/1612.01202</a></li>
  <li>github: <a href="https://github.com/ralpguler/DenseReg">https://github.com/ralpguler/DenseReg</a></li>
</ul>

<p><strong>Generalizing the Convolution Operator in Convolutional Neural Networks</strong></p>

<p><a href="https://arxiv.org/abs/1707.09864">https://arxiv.org/abs/1707.09864</a></p>

<p><strong>Convolution with Logarithmic Filter Groups for Efficient Shallow CNN</strong></p>

<p><a href="https://arxiv.org/abs/1707.09855">https://arxiv.org/abs/1707.09855</a></p>

<p><strong>Deep Multi-View Learning with Stochastic Decorrelation Loss</strong></p>

<p><a href="https://arxiv.org/abs/1707.09669">https://arxiv.org/abs/1707.09669</a></p>

<h2 id="tutorials-and-surveys">Tutorials and Surveys</h2>

<p><strong>On the Origin of Deep Learning</strong></p>

<ul>
  <li>intro: CMU. 70 pages, 200 references</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.07800">https://arxiv.org/abs/1702.07800</a></li>
</ul>

<p><strong>Efficient Processing of Deep Neural Networks: A Tutorial and Survey</strong></p>

<ul>
  <li>intro: MIT</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.09039">https://arxiv.org/abs/1703.09039</a></li>
</ul>

<h2 id="dive-into-cnn">Dive Into CNN</h2>

<p><strong>Structured Receptive Fields in CNNs</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1605.02971">https://arxiv.org/abs/1605.02971</a></li>
  <li>github: <a href="https://github.com/jhjacobsen/RFNN">https://github.com/jhjacobsen/RFNN</a></li>
</ul>

<p><strong>How ConvNets model Non-linear Transformations</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.07664">https://arxiv.org/abs/1702.07664</a></li>
</ul>

<h2 id="separable-convolutions--grouped-convolutions">Separable Convolutions / Grouped Convolutions</h2>

<p><strong>Factorized Convolutional Neural Networks</strong></p>

<p><strong>Design of Efficient Convolutional Layers using Single Intra-channel Convolution, Topological Subdivisioning and Spatial “Bottleneck” Structure</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1608.04337">http://arxiv.org/abs/1608.04337</a></li>
</ul>

<p><strong>Deep Learning with Separable Convolutions</strong></p>

<p><strong>Xception: Deep Learning with Depthwise Separable Convolutions</strong></p>

<ul>
  <li>intro: Extreme Inception</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1610.02357">https://arxiv.org/abs/1610.02357</a></li>
  <li>code: <a href="https://keras.io/applications/#xception">https://keras.io/applications/#xception</a></li>
  <li>github(Keras): <a href="https://github.com/fchollet/deep-learning-models/blob/master/xception.py">https://github.com/fchollet/deep-learning-models/blob/master/xception.py</a></li>
  <li>github: <a href="https://gist.github.com/culurciello/554c8e56d3bbaf7c66bf66c6089dc221">https://gist.github.com/culurciello/554c8e56d3bbaf7c66bf66c6089dc221</a></li>
  <li>github: <a href="https://github.com/kwotsin/Tensorflow-Xception">https://github.com/kwotsin/Tensorflow-Xception</a></li>
  <li>notes: <a href="http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1610.02357">http://www.shortscience.org/paper?bibtexKey=journals%2Fcorr%2F1610.02357</a></li>
</ul>

<p><strong>Towards a New Interpretation of Separable Convolutions</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1701.04489">https://arxiv.org/abs/1701.04489</a></li>
</ul>

<h2 id="mobilenets">MobileNets</h2>

<p><strong>MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</strong></p>

<ul>
  <li>intro: Google</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1704.04861">https://arxiv.org/abs/1704.04861</a></li>
  <li>github: <a href="https://github.com/rcmalli/keras-mobilenet">https://github.com/rcmalli/keras-mobilenet</a></li>
  <li>github: <a href="https://github.com/marvis/pytorch-mobilenet">https://github.com/marvis/pytorch-mobilenet</a></li>
  <li>github(Tensorflow): <a href="https://github.com/Zehaos/MobileNet">https://github.com/Zehaos/MobileNet</a></li>
  <li>github: <a href="https://github.com/shicai/MobileNet-Caffe">https://github.com/shicai/MobileNet-Caffe</a></li>
  <li>github: <a href="https://github.com/hollance/MobileNet-CoreML">https://github.com/hollance/MobileNet-CoreML</a></li>
  <li>github: <a href="https://github.com/KeyKy/mobilenet-mxnet">https://github.com/KeyKy/mobilenet-mxnet</a></li>
</ul>

<p><strong>MobileNets: Open-Source Models for Efficient On-Device Vision</strong></p>

<ul>
  <li>blog: <a href="https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html">https://research.googleblog.com/2017/06/mobilenets-open-source-models-for.html</a></li>
  <li>github: <a href="https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md">https://github.com/tensorflow/models/blob/master/slim/nets/mobilenet_v1.md</a></li>
</ul>

<p><strong>Google’s MobileNets on the iPhone</strong></p>

<ul>
  <li>blog: <a href="http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/">http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/</a></li>
  <li>github: <a href="https://github.com/hollance/MobileNet-CoreML">https://github.com/hollance/MobileNet-CoreML</a></li>
</ul>

<p><strong>ShuffleNet: An Extremely Efficient Convolutional Neural Network for Mobile Devices</strong></p>

<ul>
  <li>intro: Megvii Inc (Face++)</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.01083">https://arxiv.org/abs/1707.01083</a></li>
</ul>

<h2 id="stdp">STDP</h2>

<p><strong>A biological gradient descent for prediction through a combination of STDP and homeostatic plasticity</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1206.4812">http://arxiv.org/abs/1206.4812</a></li>
</ul>

<p><strong>An objective function for STDP</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1509.05936">http://arxiv.org/abs/1509.05936</a></li>
</ul>

<p><strong>Towards a Biologically Plausible Backprop</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1602.05179">http://arxiv.org/abs/1602.05179</a></li>
</ul>

<h2 id="target-propagation">Target Propagation</h2>

<p><strong>How Auto-Encoders Could Provide Credit Assignment in Deep Networks via Target Propagation</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1407.7906">http://arxiv.org/abs/1407.7906</a></li>
</ul>

<p><strong>Difference Target Propagation</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1412.7525">http://arxiv.org/abs/1412.7525</a></li>
  <li>github: <a href="https://github.com/donghyunlee/dtp">https://github.com/donghyunlee/dtp</a></li>
</ul>

<h2 id="zero-shot-learning">Zero Shot Learning</h2>

<p><strong>Learning a Deep Embedding Model for Zero-Shot Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.05088">https://arxiv.org/abs/1611.05088</a></li>
</ul>

<p><strong>Zero-Shot (Deep) Learning</strong></p>

<p><a href="https://amundtveit.com/2016/11/18/zero-shot-deep-learning/">https://amundtveit.com/2016/11/18/zero-shot-deep-learning/</a></p>

<p><strong>Zero-shot learning experiments by deep learning.</strong></p>

<p><a href="https://github.com/Elyorcv/zsl-deep-learning">https://github.com/Elyorcv/zsl-deep-learning</a></p>

<p><strong>Semantic Autoencoder for Zero-Shot Learning</strong></p>

<ul>
  <li>intro: CVPR 2017</li>
  <li>project page: <a href="https://elyorcv.github.io/projects/sae">https://elyorcv.github.io/projects/sae</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1704.08345">https://arxiv.org/abs/1704.08345</a></li>
  <li>github: <a href="https://github.com/Elyorcv/SAE">https://github.com/Elyorcv/SAE</a></li>
</ul>

<h2 id="one-shot-learning">One Shot Learning</h2>

<p><strong>One-shot Learning with Memory-Augmented Neural Networks</strong></p>

<ul>
  <li>intro: Google DeepMind</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1605.06065">https://arxiv.org/abs/1605.06065</a></li>
  <li>github(Tensorflow): <a href="https://github.com/hmishra2250/NTM-One-Shot-TF">https://github.com/hmishra2250/NTM-One-Shot-TF</a></li>
  <li>note: <a href="http://rylanschaeffer.github.io/content/research/one_shot_learning_with_memory_augmented_nn/main.html">http://rylanschaeffer.github.io/content/research/one_shot_learning_with_memory_augmented_nn/main.html</a></li>
</ul>

<p><strong>Matching Networks for One Shot Learning</strong></p>

<ul>
  <li>intro: Google DeepMind</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1606.04080">https://arxiv.org/abs/1606.04080</a></li>
  <li>notes: <a href="https://blog.acolyer.org/2017/01/03/matching-networks-for-one-shot-learning/">https://blog.acolyer.org/2017/01/03/matching-networks-for-one-shot-learning/</a></li>
</ul>

<p><strong>Learning feed-forward one-shot learners [NIPS 2016] [VALSE seminar]</strong></p>

<ul>
  <li>youtube: <a href="https://www.youtube.com/watch?v=BnLN3uoXMRY">https://www.youtube.com/watch?v=BnLN3uoXMRY</a></li>
  <li>mirror: <a href="https://pan.baidu.com/s/1mhAITmS">https://pan.baidu.com/s/1mhAITmS</a></li>
</ul>

<p><strong>Generative Adversarial Residual Pairwise Networks for One Shot Learning</strong></p>

<ul>
  <li>intro: Indian Institute of Science</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1703.08033">https://arxiv.org/abs/1703.08033</a></li>
</ul>

<h2 id="few-shot-learning">Few-Shot Learning</h2>

<p><strong>Optimization as a Model for Few-Shot Learning</strong></p>

<ul>
  <li>intro: Twitter</li>
  <li>paper: <a href="https://openreview.net/pdf?id=rJY0-Kcll">https://openreview.net/pdf?id=rJY0-Kcll</a></li>
  <li>github: <a href="https://github.com/twitter/meta-learning-lstm">https://github.com/twitter/meta-learning-lstm</a></li>
</ul>

<h2 id="incremental-learning">Incremental Learning</h2>

<p><strong>iCaRL: Incremental Classifier and Representation Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.07725">https://arxiv.org/abs/1611.07725</a></li>
</ul>

<h2 id="ensemble-deep-learning">Ensemble Deep Learning</h2>

<p><strong>Convolutional Neural Fabrics</strong></p>

<ul>
  <li>intro: NIPS 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1606.02492">http://arxiv.org/abs/1606.02492</a></li>
  <li>github: <a href="https://github.com/shreyassaxena/convolutional-neural-fabrics">https://github.com/shreyassaxena/convolutional-neural-fabrics</a></li>
</ul>

<p><strong>Stochastic Multiple Choice Learning for Training Diverse Deep Ensembles</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1606.07839">https://arxiv.org/abs/1606.07839</a></li>
  <li>youtube: <a href="https://www.youtube.com/watch?v=KjUfMtZjyfg&amp;feature=youtu.be">https://www.youtube.com/watch?v=KjUfMtZjyfg&amp;feature=youtu.be</a></li>
</ul>

<p><strong>Snapshot Ensembles: Train 1, Get M for Free</strong></p>

<ul>
  <li>paper: <a href="http://openreview.net/pdf?id=BJYwwY9ll">http://openreview.net/pdf?id=BJYwwY9ll</a></li>
  <li>github(Torch): <a href="https://github.com/gaohuang/SnapshotEnsemble">https://github.com/gaohuang/SnapshotEnsemble</a></li>
  <li>github: <a href="https://github.com/titu1994/Snapshot-Ensembles">https://github.com/titu1994/Snapshot-Ensembles</a></li>
</ul>

<p><strong>Ensemble Deep Learning</strong></p>

<ul>
  <li>blog: <a href="https://amundtveit.com/2016/12/02/ensemble-deep-learning/">https://amundtveit.com/2016/12/02/ensemble-deep-learning/</a></li>
</ul>

<h2 id="embedding">Embedding</h2>

<p><strong>Full-Network Embedding in a Multimodal Embedding Pipeline</strong></p>

<p><a href="https://arxiv.org/abs/1707.09872">https://arxiv.org/abs/1707.09872</a></p>

<h2 id="computer-vision">Computer Vision</h2>

<p><strong>A Taxonomy of Deep Convolutional Neural Nets for Computer Vision</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1601.06615">http://arxiv.org/abs/1601.06615</a></li>
</ul>

<p><strong>On the usability of deep networks for object-based image analysis</strong></p>

<ul>
  <li>intro: GEOBIA 2016</li>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.06845">http://arxiv.org/abs/1609.06845</a></li>
</ul>

<p><strong>Learning Recursive Filters for Low-Level Vision via a Hybrid Neural Network</strong></p>

<ul>
  <li>intro: ECCV 2016</li>
  <li>project page: <a href="http://www.sifeiliu.net/linear-rnn">http://www.sifeiliu.net/linear-rnn</a></li>
  <li>paper: <a href="http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf">http://faculty.ucmerced.edu/mhyang/papers/eccv16_rnn_filter.pdf</a></li>
  <li>poster: <a href="http://www.eccv2016.org/files/posters/O-3A-03.pdf">http://www.eccv2016.org/files/posters/O-3A-03.pdf</a></li>
  <li>github: <a href="https://github.com/Liusifei/caffe-lowlevel">https://github.com/Liusifei/caffe-lowlevel</a></li>
</ul>

<p><strong>DSAC - Differentiable RANSAC for Camera Localization</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.05705">https://arxiv.org/abs/1611.05705</a></li>
</ul>

<p><strong>Toward Geometric Deep SLAM</strong></p>

<ul>
  <li>intro: Magic Leap, Inc</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1707.07410">https://arxiv.org/abs/1707.07410</a></li>
</ul>

<h3 id="optical-flow">Optical Flow</h3>

<p><strong>FlowNet: Learning Optical Flow with Convolutional Networks</strong></p>

<ul>
  <li>intro: “competitive accuracy at frame rates of 5 to 10 fps”</li>
  <li>project page: <a href="http://lmb.informatik.uni-freiburg.de/Publications/2015/DFIB15/">http://lmb.informatik.uni-freiburg.de/Publications/2015/DFIB15/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1504.06852">https://arxiv.org/abs/1504.06852</a></li>
  <li>github: <a href="https://github.com/ClementPinard/FlowNetTorch">https://github.com/ClementPinard/FlowNetTorch</a></li>
  <li>github: <a href="https://github.com/ClementPinard/FlowNetPytorch">https://github.com/ClementPinard/FlowNetPytorch</a></li>
</ul>

<p><strong>FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks</strong></p>

<ul>
  <li>intro: CVPR 2017</li>
  <li>project page: <a href="http://lmb.informatik.uni-freiburg.de/Publications/2016/IMKDB16/">http://lmb.informatik.uni-freiburg.de/Publications/2016/IMKDB16/</a></li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.01925">https://arxiv.org/abs/1612.01925</a></li>
  <li>github(Caffe): <a href="https://github.com/lmb-freiburg/flownet2">https://github.com/lmb-freiburg/flownet2</a></li>
  <li>video: <a href="http://lmb.informatik.uni-freiburg.de/Publications/2016/IMKDB16/">http://lmb.informatik.uni-freiburg.de/Publications/2016/IMKDB16/</a></li>
</ul>

<p><strong>Optical Flow Estimation using a Spatial Pyramid Network</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00850">https://arxiv.org/abs/1611.00850</a></li>
</ul>

<p><strong>Guided Optical Flow Learning</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.02295">https://arxiv.org/abs/1702.02295</a></li>
</ul>

<h3 id="all-in-one-network">All-In-One Network</h3>

<p><strong>HyperFace: A Deep Multi-task Learning Framework for Face Detection, Landmark Localization, Pose Estimation, and Gender Recognition</strong></p>

<ul>
  <li>arxiv: <a href="https://arxiv.org/abs/1603.01249">https://arxiv.org/abs/1603.01249</a></li>
  <li>summary: <a href="https://github.com/aleju/papers/blob/master/neural-nets/HyperFace.md">https://github.com/aleju/papers/blob/master/neural-nets/HyperFace.md</a></li>
</ul>

<p><strong>UberNet: Training a `Universal’ Convolutional Neural Network for Low-, Mid-, and High-Level Vision using Diverse Datasets and Limited Memory</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1609.02132">http://arxiv.org/abs/1609.02132</a></li>
  <li>demo: <a href="http://cvn.ecp.fr/ubernet/">http://cvn.ecp.fr/ubernet/</a></li>
</ul>

<p><strong>An All-In-One Convolutional Neural Network for Face Analysis</strong></p>

<ul>
  <li>intro: simultaneous face detection, face alignment, pose estimation, gender recognition, smile detection, age estimation and face recognition</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1611.00851">https://arxiv.org/abs/1611.00851</a></li>
</ul>

<p><strong>MultiNet: Real-time Joint Semantic Reasoning for Autonomous Driving</strong></p>

<ul>
  <li>intro: first place on Kitti Road Segmentation. 
joint classification, detection and semantic segmentation via a unified architecture, less than 100 ms to perform all tasks</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1612.07695">https://arxiv.org/abs/1612.07695</a></li>
  <li>github: <a href="https://github.com/MarvinTeichmann/MultiNet">https://github.com/MarvinTeichmann/MultiNet</a></li>
</ul>

<h1 id="projects">Projects</h1>

<p><strong>Top Deep Learning Projects</strong></p>

<ul>
  <li>github: <a href="https://github.com/aymericdamien/TopDeepLearning">https://github.com/aymericdamien/TopDeepLearning</a></li>
</ul>

<p><strong>deepnet: Implementation of some deep learning algorithms</strong></p>

<ul>
  <li>github: <a href="https://github.com/nitishsrivastava/deepnet">https://github.com/nitishsrivastava/deepnet</a></li>
</ul>

<p><strong>DeepNeuralClassifier(Julia): Deep neural network using rectified linear units to classify hand written digits from the MNIST dataset</strong></p>

<ul>
  <li>github: <a href="https://github.com/jostmey/DeepNeuralClassifier">https://github.com/jostmey/DeepNeuralClassifier</a></li>
</ul>

<p><strong>Clarifai Node.js Demo</strong></p>

<ul>
  <li>github: <a href="https://github.com/patcat/Clarifai-Node-Demo">https://github.com/patcat/Clarifai-Node-Demo</a></li>
  <li>blog(“How to Make Your Web App Smarter with Image Recognition”): <a href="http://www.sitepoint.com/how-to-make-your-web-app-smarter-with-image-recognition/">http://www.sitepoint.com/how-to-make-your-web-app-smarter-with-image-recognition/</a></li>
</ul>

<p><strong>Deep Learning in Rust</strong></p>

<ul>
  <li>blog(“baby steps”): <a href="https://medium.com/@tedsta/deep-learning-in-rust-7e228107cccc#.t0pskuwkm">https://medium.com/@tedsta/deep-learning-in-rust-7e228107cccc#.t0pskuwkm</a></li>
  <li>blog(“a walk in the park”): <a href="https://medium.com/@tedsta/deep-learning-in-rust-a-walk-in-the-park-fed6c87165ea#.pucj1l5yx">https://medium.com/@tedsta/deep-learning-in-rust-a-walk-in-the-park-fed6c87165ea#.pucj1l5yx</a></li>
  <li>github: <a href="https://github.com/tedsta/deeplearn-rs">https://github.com/tedsta/deeplearn-rs</a></li>
</ul>

<p><strong>Implementation of state-of-art models in Torch</strong></p>

<ul>
  <li>github: <a href="https://github.com/aciditeam/torch-models">https://github.com/aciditeam/torch-models</a></li>
</ul>

<p><strong>Deep Learning (Python, C, C++, Java, Scala, Go)</strong></p>

<ul>
  <li>github: <a href="https://github.com/yusugomori/DeepLearning">https://github.com/yusugomori/DeepLearning</a></li>
</ul>

<p><strong>deepmark: THE Deep Learning Benchmarks</strong></p>

<ul>
  <li>github: <a href="https://github.com/DeepMark/deepmark">https://github.com/DeepMark/deepmark</a></li>
</ul>

<p><strong>Siamese Net</strong></p>

<ul>
  <li>intro: “This package shows how to train a siamese network using Lasagne and Theano and includes network definitions 
for state-of-the-art networks including: DeepID, DeepID2, Chopra et. al, and Hani et. al. 
We also include one pre-trained model using a custom convolutional network.”</li>
  <li>github: <a href="https://github.com/Kadenze/siamese_net">https://github.com/Kadenze/siamese_net</a></li>
</ul>

<p><strong>PRE-TRAINED CONVNETS AND OBJECT LOCALISATION IN KERAS</strong></p>

<ul>
  <li>blog: <a href="https://blog.heuritech.com/2016/04/26/pre-trained-convnets-and-object-localisation-in-keras/">https://blog.heuritech.com/2016/04/26/pre-trained-convnets-and-object-localisation-in-keras/</a></li>
  <li>github: <a href="https://github.com/heuritech/convnets-keras">https://github.com/heuritech/convnets-keras</a></li>
</ul>

<p><strong>Deep Learning algorithms with TensorFlow: Ready to use implementations of various Deep Learning algorithms using TensorFlow</strong></p>

<ul>
  <li>homepage: <a href="http://www.gabrieleangeletti.com/">http://www.gabrieleangeletti.com/</a></li>
  <li>github: <a href="https://github.com/blackecho/Deep-Learning-TensorFlow">https://github.com/blackecho/Deep-Learning-TensorFlow</a></li>
</ul>

<p><strong>Fast Multi-threaded VGG 19 Feature Extractor</strong></p>

<ul>
  <li>github: <a href="https://github.com/coreylynch/vgg-19-feature-extractor">https://github.com/coreylynch/vgg-19-feature-extractor</a></li>
</ul>

<p><strong>Live demo of neural network classifying images</strong></p>

<p><img src="/assets/cnn-materials/nn_classify_images_live_demo.jpg" height="300" alt="" /></p>

<p><a href="http://ml4a.github.io/dev/demos/cifar_confusion.html#">http://ml4a.github.io/dev/demos/cifar_confusion.html#</a></p>

<p><strong>mojo cnn: c++ convolutional neural network</strong></p>

<ul>
  <li>intro: the fast and easy header only c++ convolutional neural network package</li>
  <li>github: <a href="https://github.com/gnawice/mojo-cnn">https://github.com/gnawice/mojo-cnn</a></li>
</ul>

<p><strong>DeepHeart: Neural networks for monitoring cardiac data</strong></p>

<ul>
  <li>github: <a href="https://github.com/jisaacso/DeepHeart">https://github.com/jisaacso/DeepHeart</a></li>
</ul>

<p><strong>Deep Water: Deep Learning in H2O using Native GPU Backends</strong></p>

<ul>
  <li>intro: Native implementation of Deep Learning models for GPU backends (mxnet, Caffe, TensorFlow, etc.)</li>
  <li>github: <a href="https://github.com/h2oai/deepwater">https://github.com/h2oai/deepwater</a></li>
</ul>

<p><strong>Greentea LibDNN: Greentea LibDNN - a universal convolution implementation supporting CUDA and OpenCL</strong></p>

<ul>
  <li>github: <a href="https://github.com/naibaf7/libdnn">https://github.com/naibaf7/libdnn</a></li>
</ul>

<p><strong>Dracula: A spookily good Part of Speech Tagger optimized for Twitter</strong></p>

<ul>
  <li>intro: A deep, LSTM-based part of speech tagger and sentiment analyser using character embeddings instead of words. 
Compatible with Theano and TensorFlow. Optimized for Twitter.</li>
  <li>homepage: <a href="http://dracula.sentimentron.co.uk/">http://dracula.sentimentron.co.uk/</a></li>
  <li>speech tagging demo: <a href="http://dracula.sentimentron.co.uk/pos-demo/">http://dracula.sentimentron.co.uk/pos-demo/</a></li>
  <li>sentiment demo: <a href="http://dracula.sentimentron.co.uk/sentiment-demo/">http://dracula.sentimentron.co.uk/sentiment-demo/</a></li>
  <li>github: <a href="https://github.com/Sentimentron/Dracula">https://github.com/Sentimentron/Dracula</a></li>
</ul>

<p><strong>Trained image classification models for Keras</strong></p>

<ul>
  <li>intro: Keras code and weights files for popular deep learning models.</li>
  <li>intro: VGG16, VGG19, ResNet50, Inception v3</li>
  <li>github: <a href="https://github.com/fchollet/deep-learning-models">https://github.com/fchollet/deep-learning-models</a></li>
</ul>

<p><strong>PyCNN: Cellular Neural Networks Image Processing Python Library</strong></p>

<p><img src="https://camo.githubusercontent.com/0c5fd234a144b3d2145a133466766b2ecd9d3f3c/687474703a2f2f7777772e6973697765622e65652e6574687a2e63682f6861656e6767692f434e4e5f7765622f434e4e5f666967757265732f626c6f636b6469616772616d2e676966" height="300" alt="" /></p>

<ul>
  <li>blog: <a href="http://blog.ankitaggarwal.me/PyCNN/">http://blog.ankitaggarwal.me/PyCNN/</a></li>
  <li>github: <a href="https://github.com/ankitaggarwal011/PyCNN">https://github.com/ankitaggarwal011/PyCNN</a></li>
</ul>

<p><strong>regl-cnn: Digit recognition with Convolutional Neural Networks in WebGL</strong></p>

<ul>
  <li>intro: TensorFlow, WebGL, <a href="https://github.com/mikolalysenko/regl">regl</a></li>
  <li>github: <a href="https://github.com/Erkaman/regl-cnn/">https://github.com/Erkaman/regl-cnn/</a></li>
  <li>demo: <a href="https://erkaman.github.io/regl-cnn/src/demo.html">https://erkaman.github.io/regl-cnn/src/demo.html</a></li>
</ul>

<p><strong>dagstudio: Directed Acyclic Graph Studio with Javascript D3</strong></p>

<p><img src="https://raw.githubusercontent.com/TimZaman/dagstudio/master/misc/20160907_dagstudio_ex.gif" height="300" alt="" /></p>

<ul>
  <li>github: <a href="https://github.com/TimZaman/dagstudio">https://github.com/TimZaman/dagstudio</a></li>
</ul>

<p><strong>NEUGO: Neural Networks in Go</strong></p>

<ul>
  <li>github: <a href="https://github.com/wh1t3w01f/neugo">https://github.com/wh1t3w01f/neugo</a></li>
</ul>

<p><strong>gvnn: Neural Network Library for Geometric Computer Vision</strong></p>

<ul>
  <li>arxiv: <a href="http://arxiv.org/abs/1607.07405">http://arxiv.org/abs/1607.07405</a></li>
  <li>github: <a href="https://github.com/ankurhanda/gvnn">https://github.com/ankurhanda/gvnn</a></li>
</ul>

<p><strong>DeepForge: A development environment for deep learning</strong></p>

<ul>
  <li>github: <a href="https://github.com/dfst/deepforge">https://github.com/dfst/deepforge</a></li>
</ul>

<p><strong>Implementation of recent Deep Learning papers</strong></p>

<ul>
  <li>intro: DenseNet / DeconvNet / DenseRecNet</li>
  <li>github: <a href="https://github.com/tdeboissiere/DeepLearningImplementations">https://github.com/tdeboissiere/DeepLearningImplementations</a></li>
</ul>

<p><strong>GPU-accelerated Theano &amp; Keras on Windows 10 native</strong></p>

<ul>
  <li>github: <a href="https://github.com/philferriere/dlwin">https://github.com/philferriere/dlwin</a></li>
</ul>

<p><strong>Head Pose and Gaze Direction Estimation Using Convolutional Neural Networks</strong></p>

<ul>
  <li>github: <a href="https://github.com/mpatacchiola/deepgaze">https://github.com/mpatacchiola/deepgaze</a></li>
</ul>

<p><strong>Intel(R) Math Kernel Library for Deep Neural Networks (Intel(R) MKL-DNN)</strong></p>

<ul>
  <li>homepage: <a href="https://01.org/mkl-dnn">https://01.org/mkl-dnn</a></li>
  <li>github: <a href="https://github.com/01org/mkl-dnn">https://github.com/01org/mkl-dnn</a></li>
</ul>

<p><strong>Deep CNN and RNN - Deep convolution/recurrent neural network project with TensorFlow</strong></p>

<ul>
  <li>github: <a href="https://github.com/tobegit3hub/deep_cnn">https://github.com/tobegit3hub/deep_cnn</a></li>
</ul>

<p><strong>Experimental implementation of novel neural network structures</strong></p>

<ul>
  <li>intro: binarynet / ternarynet / qrnn / vae / gcnn</li>
  <li>github: <a href="https://github.com/DingKe/nn_playground">https://github.com/DingKe/nn_playground</a></li>
</ul>

<p><strong>WaterNet: A convolutional neural network that identifies water in satellite images</strong></p>

<ul>
  <li>github: <a href="https://github.com/treigerm/WaterNet">https://github.com/treigerm/WaterNet</a></li>
</ul>

<p><strong>Kur: Descriptive Deep Learning</strong></p>

<ul>
  <li>github: <a href="https://github.com/deepgram/kur">https://github.com/deepgram/kur</a></li>
  <li>docs: <a href="http://kur.deepgram.com/">http://kur.deepgram.com/</a></li>
</ul>

<p><strong>Development of JavaScript-based deep learning platform and application to distributed training</strong></p>

<ul>
  <li>intro: Workshop paper for ICLR2017</li>
  <li>arxiv: <a href="https://arxiv.org/abs/1702.01846">https://arxiv.org/abs/1702.01846</a></li>
  <li>github: <a href="https://github.com/mil-tokyo">https://github.com/mil-tokyo</a></li>
</ul>

<p><strong>NewralNet</strong></p>

<ul>
  <li>intro: A lightweight, easy to use and open source Java library for experimenting with
feed-forward neural nets and deep learning.</li>
  <li>gitlab: <a href="https://gitlab.com/flimmerkiste/NewralNet">https://gitlab.com/flimmerkiste/NewralNet</a></li>
</ul>

<h1 id="readings-and-questions">Readings and Questions</h1>

<p><strong>What you wanted to know about AI</strong></p>

<p><a href="http://fastml.com/what-you-wanted-to-know-about-ai/">http://fastml.com/what-you-wanted-to-know-about-ai/</a></p>

<p><strong>Epoch vs iteration when training neural networks</strong></p>

<ul>
  <li>stackoverflow: <a href="http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks">http://stackoverflow.com/questions/4752626/epoch-vs-iteration-when-training-neural-networks</a></li>
</ul>

<p><strong>Questions to Ask When Applying Deep Learning</strong></p>

<p><a href="http://deeplearning4j.org/questions.html">http://deeplearning4j.org/questions.html</a></p>

<p><strong>How can I know if Deep Learning works better for a specific problem than SVM or random forest?</strong></p>

<ul>
  <li>github: <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md">https://github.com/rasbt/python-machine-learning-book/blob/master/faq/deeplearn-vs-svm-randomforest.md</a></li>
</ul>

<p><strong>What is the difference between deep learning and usual machine learning?</strong></p>

<ul>
  <li>note: <a href="https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md">https://github.com/rasbt/python-machine-learning-book/blob/master/faq/difference-deep-and-normal-learning.md</a></li>
</ul>

<h1 id="resources">Resources</h1>

<p><strong>Awesome Deep Learning</strong></p>

<ul>
  <li>github: <a href="https://github.com/ChristosChristofidis/awesome-deep-learning">https://github.com/ChristosChristofidis/awesome-deep-learning</a></li>
</ul>

<p><strong>Awesome-deep-vision: A curated list of deep learning resources for computer vision</strong></p>

<ul>
  <li>website: <a href="http://jiwonkim.org/awesome-deep-vision/">http://jiwonkim.org/awesome-deep-vision/</a></li>
  <li>github: <a href="https://github.com/kjw0612/awesome-deep-vision">https://github.com/kjw0612/awesome-deep-vision</a></li>
</ul>

<p><strong>Applied Deep Learning Resources: A collection of research articles, blog posts, slides and code snippets about deep learning in applied settings.</strong></p>

<ul>
  <li>github: <a href="https://github.com/kristjankorjus/applied-deep-learning-resources">https://github.com/kristjankorjus/applied-deep-learning-resources</a></li>
</ul>

<p><strong>Deep Learning Libraries by Language</strong></p>

<ul>
  <li>website: <a href="http://www.teglor.com/b/deep-learning-libraries-language-cm569/">http://www.teglor.com/b/deep-learning-libraries-language-cm569/</a></li>
</ul>

<p><strong>Deep Learning Resources</strong></p>

<p><a href="http://yanirseroussi.com/deep-learning-resources/">http://yanirseroussi.com/deep-learning-resources/</a></p>

<p><strong>Deep Learning Resources</strong></p>

<p><a href="https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html">https://omtcyfz.github.io/2016/08/29/Deep-Learning-Resources.html</a></p>

<p><strong>Turing Machine: musings on theory &amp; code(DEEP LEARNING REVOLUTION, summer 2015, state of the art &amp; topnotch links)</strong></p>

<p><a href="https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/">https://vzn1.wordpress.com/2015/09/01/deep-learning-revolution-summer-2015-state-of-the-art-topnotch-links/</a></p>

<p><strong>BICV Group: Biologically Inspired Computer Vision research group</strong></p>

<p><a href="http://www.bicv.org/deep-learning/">http://www.bicv.org/deep-learning/</a></p>

<p><strong>Learning Deep Learning</strong></p>

<p><a href="http://rt.dgyblog.com/ref/ref-learning-deep-learning.html">http://rt.dgyblog.com/ref/ref-learning-deep-learning.html</a></p>

<p><strong>Summaries and notes on Deep Learning research papers</strong></p>

<ul>
  <li>github: <a href="https://github.com/dennybritz/deeplearning-papernotes">https://github.com/dennybritz/deeplearning-papernotes</a></li>
</ul>

<p><strong>Deep Learning Glossary</strong></p>

<ul>
  <li>intro: “Simple, opinionated explanations of various things encountered in Deep Learning / AI / ML.”</li>
  <li>author: Ryan Dahl, author of NodeJS.</li>
  <li>github: <a href="https://github.com/ry/deep_learning_glossary">https://github.com/ry/deep_learning_glossary</a></li>
</ul>

<p><strong>The Deep Learning Playbook</strong></p>

<p><a href="https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a#.eg9cdz5ak">https://medium.com/@jiefeng/deep-learning-playbook-c5ebe34f8a1a#.eg9cdz5ak</a></p>

<p><strong>Deep Learning Study: Study of HeXA@UNIST in Preparation for Submission</strong></p>

<ul>
  <li>github: <a href="https://github.com/carpedm20/deep-learning-study">https://github.com/carpedm20/deep-learning-study</a></li>
</ul>

<p><strong>Deep Learning Books</strong></p>

<ul>
  <li>blog: <a href="http://machinelearningmastery.com/deep-learning-books/">http://machinelearningmastery.com/deep-learning-books/</a></li>
</ul>

<p><strong>awesome-very-deep-learning: A curated list of papers and code about very deep neural networks (50+ layers)</strong></p>

<ul>
  <li>github: <a href="https://github.com/daviddao/awesome-very-deep-learning">https://github.com/daviddao/awesome-very-deep-learning</a></li>
</ul>

<p><strong>Deep Learning Resources and Tutorials using Keras and Lasagne</strong></p>

<ul>
  <li>github: <a href="https://github.com/Vict0rSch/deep_learning">https://github.com/Vict0rSch/deep_learning</a></li>
</ul>

<p><strong>Deep Learning: Definition, Resources, Comparison with Machine Learning</strong></p>

<ul>
  <li>blog: <a href="http://www.datasciencecentral.com/profiles/blogs/deep-learning-definition-resources-comparison-with-machine-learni">http://www.datasciencecentral.com/profiles/blogs/deep-learning-definition-resources-comparison-with-machine-learni</a></li>
</ul>

<p><strong>Awesome - Most Cited Deep Learning Papers</strong></p>

<ul>
  <li>github: <a href="https://github.com/terryum/awesome-deep-learning-papers">https://github.com/terryum/awesome-deep-learning-papers</a></li>
</ul>

<p><strong>The most cited papers in computer vision and deep learning</strong></p>

<ul>
  <li>blog: <a href="https://computervisionblog.wordpress.com/2016/06/19/the-most-cited-papers-in-computer-vision-and-deep-learning/">https://computervisionblog.wordpress.com/2016/06/19/the-most-cited-papers-in-computer-vision-and-deep-learning/</a></li>
</ul>

<p><strong>deep learning papers: A place to collect papers that are related to deep learning and computational biology</strong></p>

<ul>
  <li>github: <a href="https://github.com/pimentel/deep_learning_papers">https://github.com/pimentel/deep_learning_papers</a></li>
</ul>

<p><strong>papers-I-read</strong></p>

<ul>
  <li>intro: “I am trying a new initiative - a-paper-a-week. This repository will hold all those papers and related summaries and notes.”</li>
  <li>github: <a href="https://github.com/shagunsodhani/papers-I-read">https://github.com/shagunsodhani/papers-I-read</a></li>
</ul>

<p><strong>LEARNING DEEP LEARNING - MY TOP-FIVE LIST</strong></p>

<ul>
  <li>blog: <a href="http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/">http://thegrandjanitor.com/2016/08/15/learning-deep-learning-my-top-five-resource/</a></li>
</ul>

<p><strong>awesome-free-deep-learning-papers</strong></p>

<ul>
  <li>github: <a href="https://github.com/HFTrader/awesome-free-deep-learning-papers">https://github.com/HFTrader/awesome-free-deep-learning-papers</a></li>
</ul>

<p><strong>DeepLearningBibliography: Bibliography for Publications about Deep Learning using GPU</strong></p>

<ul>
  <li>homepage: <a href="http://memkite.com/deep-learning-bibliography/">http://memkite.com/deep-learning-bibliography/</a></li>
  <li>github: <a href="https://github.com/memkite/DeepLearningBibliography">https://github.com/memkite/DeepLearningBibliography</a></li>
</ul>

<p><strong>Deep Learning Papers Reading Roadmap</strong></p>

<ul>
  <li>github: <a href="https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap">https://github.com/songrotek/Deep-Learning-Papers-Reading-Roadmap</a></li>
</ul>

<p><strong>deep-learning-papers</strong></p>

<ul>
  <li>intro: Papers about deep learning ordered by task, date. Current state-of-the-art papers are labelled.</li>
  <li>github: <a href="https://github.com/sbrugman/deep-learning-papers/blob/master/README.md">https://github.com/sbrugman/deep-learning-papers/blob/master/README.md</a></li>
</ul>

<p><strong>Deep Learning and applications in Startups, CV, Text Mining, NLP</strong></p>

<ul>
  <li>github: <a href="https://github.com/lipiji/app-dl">https://github.com/lipiji/app-dl</a></li>
</ul>

<p><strong>ml4a-guides - a collection of practical resources for working with machine learning software, including code and tutorials</strong></p>

<p><a href="http://ml4a.github.io/guides/">http://ml4a.github.io/guides/</a></p>

<p><strong>deep-learning-resources</strong></p>

<ul>
  <li>intro: A Collection of resources I have found useful on my journey finding my way through the world of Deep Learning.</li>
  <li>github: <a href="https://github.com/chasingbob/deep-learning-resources">https://github.com/chasingbob/deep-learning-resources</a></li>
</ul>

<p><strong>21 Deep Learning Videos, Tutorials &amp; Courses on Youtube from 2016</strong></p>

<p><a href="https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/">https://www.analyticsvidhya.com/blog/2016/12/21-deep-learning-videos-tutorials-courses-on-youtube-from-2016/</a></p>

<p><strong>Awesome Deep learning papers and other resources</strong></p>

<ul>
  <li>github: <a href="https://github.com/endymecy/awesome-deeplearning-resources">https://github.com/endymecy/awesome-deeplearning-resources</a></li>
</ul>

<p><strong>awesome-deep-vision-web-demo</strong></p>

<ul>
  <li>intro: A curated list of awesome deep vision web demo</li>
  <li>github: <a href="https://github.com/hwalsuklee/awesome-deep-vision-web-demo">https://github.com/hwalsuklee/awesome-deep-vision-web-demo</a></li>
</ul>

<p><strong>Summaries of machine learning papers</strong></p>

<p><a href="https://github.com/aleju/papers">https://github.com/aleju/papers</a></p>

<p><strong>Awesome Deep Learning Resources</strong></p>

<p><a href="https://github.com/guillaume-chevalier/awesome-deep-learning-resources">https://github.com/guillaume-chevalier/awesome-deep-learning-resources</a></p>

<h2 id="arxiv-pages">Arxiv Pages</h2>

<p><strong>Neural and Evolutionary Computing</strong></p>

<p><a href="https://arxiv.org/list/cs.NE/recent">https://arxiv.org/list/cs.NE/recent</a></p>

<p><strong>Learning</strong></p>

<p><a href="https://arxiv.org/list/cs.LG/recent">https://arxiv.org/list/cs.LG/recent</a></p>

<p><strong>Computer Vision and Pattern Recognition</strong></p>

<p><a href="https://arxiv.org/list/cs.CV/recent">https://arxiv.org/list/cs.CV/recent</a></p>

<h2 id="arxiv-sanity-preserver">Arxiv Sanity Preserver</h2>

<ul>
  <li>intro: Built by @karpathy to accelerate research.</li>
  <li>page: <a href="http://www.arxiv-sanity.com/">http://www.arxiv-sanity.com/</a></li>
</ul>

<p><strong>Today’s Deep Learning</strong></p>

<p><a href="http://todaysdeeplearning.com/">http://todaysdeeplearning.com/</a></p>

<h1 id="tools">Tools</h1>

<p><strong>DNNGraph - A deep neural network model generation DSL in Haskell</strong></p>

<ul>
  <li>homepage: <a href="http://ajtulloch.github.io/dnngraph/">http://ajtulloch.github.io/dnngraph/</a></li>
</ul>

<p><strong>Deep playground: an interactive visualization of neural networks, written in typescript using d3.js</strong></p>

<ul>
  <li>homepage: <a href="http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.23990&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification">http://playground.tensorflow.org/#activation=tanh&amp;batchSize=10&amp;dataset=circle&amp;regDataset=reg-plane&amp;learningRate=0.03&amp;regularizationRate=0&amp;noise=0&amp;networkShape=4,2&amp;seed=0.23990&amp;showTestData=false&amp;discretize=false&amp;percTrainData=50&amp;x=true&amp;y=true&amp;xTimesY=false&amp;xSquared=false&amp;ySquared=false&amp;cosX=false&amp;sinX=false&amp;cosY=false&amp;sinY=false&amp;collectStats=false&amp;problem=classification</a></li>
  <li>github: <a href="https://github.com/tensorflow/playground">https://github.com/tensorflow/playground</a></li>
</ul>

<p><strong>Neural Network Package</strong></p>

<ul>
  <li>intro: This package provides an easy and modular way to build and train simple or complex neural networks using Torch</li>
  <li>github: <a href="https://github.com/torch/nn">https://github.com/torch/nn</a></li>
</ul>

<p><strong>deepdish: Deep learning and data science tools from the University of Chicago</strong>
<strong>deepdish: Serving Up Chicago-Style Deep Learning</strong></p>

<ul>
  <li>homepage: <a href="http://deepdish.io/">http://deepdish.io/</a></li>
  <li>github: <a href="https://github.com/uchicago-cs/deepdish">https://github.com/uchicago-cs/deepdish</a></li>
</ul>

<p><strong>AETROS CLI: Console application to manage deep neural network training in AETROS Trainer</strong></p>

<ul>
  <li>intro: Create, train and monitor deep neural networks using a model designer.</li>
  <li>homepage: <a href="http://aetros.com/">http://aetros.com/</a></li>
  <li>github: <a href="https://github.com/aetros/aetros-cli">https://github.com/aetros/aetros-cli</a></li>
</ul>

<p><strong>Deep Learning Studio: Cloud platform for designing Deep Learning AI without programming</strong></p>

<p><a href="http://deepcognition.ai/">http://deepcognition.ai/</a></p>

<p><strong>cuda-on-cl: Build NVIDIA® CUDA™ code for OpenCL™ 1.2 devices</strong></p>

<ul>
  <li>github: <a href="https://github.com/hughperkins/cuda-on-cl">https://github.com/hughperkins/cuda-on-cl</a></li>
</ul>

<p><strong>Receptive Field Calculator</strong></p>

<ul>
  <li>homepage: <a href="http://fomoro.com/tools/receptive-fields/">http://fomoro.com/tools/receptive-fields/</a></li>
  <li>example: <a href="http://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID">http://fomoro.com/tools/receptive-fields/#3,1,1,VALID;3,1,1,VALID;3,1,1,VALID</a></li>
</ul>

<h1 id="hackathons">Hackathons</h1>

<p><strong>VisionHack 2017</strong></p>

<ul>
  <li>intro: 10 - 14 Sep 2017, Moscow, Russia</li>
  <li>intro: a full-fledged hackathon that will last three full days</li>
  <li>homepage: <a href="http://visionhack.misis.ru/">http://visionhack.misis.ru/</a></li>
</ul>

<h1 id="books">Books</h1>

<p><strong>Deep Learning</strong></p>

<ul>
  <li>author: Ian Goodfellow, Aaron Courville and Yoshua Bengio</li>
  <li>homepage: <a href="http://www.deeplearningbook.org/">http://www.deeplearningbook.org/</a></li>
  <li>website: <a href="http://goodfeli.github.io/dlbook/">http://goodfeli.github.io/dlbook/</a></li>
  <li>github: <a href="https://github.com/HFTrader/DeepLearningBook">https://github.com/HFTrader/DeepLearningBook</a></li>
  <li>notes(“Deep Learning for Beginners”): <a href="http://randomekek.github.io/deep/deeplearning.html">http://randomekek.github.io/deep/deeplearning.html</a></li>
</ul>

<p><strong>Fundamentals of Deep Learning: Designing Next-Generation Artificial Intelligence Algorithms</strong></p>

<ul>
  <li>author: Nikhil Buduma</li>
  <li>book review: <a href="http://www.opengardensblog.futuretext.com/archives/2015/08/book-review-fundamentals-of-deep-learning-designing-next-generation-artificial-intelligence-algorithms-by-nikhil-buduma.html">http://www.opengardensblog.futuretext.com/archives/2015/08/book-review-fundamentals-of-deep-learning-designing-next-generation-artificial-intelligence-algorithms-by-nikhil-buduma.html</a></li>
  <li>github: <a href="https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book">https://github.com/darksigma/Fundamentals-of-Deep-Learning-Book</a></li>
</ul>

<p><strong>FIRST CONTACT WITH TENSORFLOW: Get started with with Deep Learning programming</strong></p>

<ul>
  <li>author: Jordi Torres</li>
  <li>book: <a href="http://www.jorditorres.org/first-contact-with-tensorflow/">http://www.jorditorres.org/first-contact-with-tensorflow/</a></li>
</ul>

<p><strong>Make Your Own Neural Network: IPython Neural Networks on a Raspberry Pi Zero</strong></p>

<ul>
  <li>book: <a href="http://makeyourownneuralnetwork.blogspot.jp/2016/03/ipython-neural-networks-on-raspberry-pi.html">http://makeyourownneuralnetwork.blogspot.jp/2016/03/ipython-neural-networks-on-raspberry-pi.html</a></li>
  <li>github: <a href="https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork">https://github.com/makeyourownneuralnetwork/makeyourownneuralnetwork</a></li>
</ul>

<h1 id="blogs">Blogs</h1>

<p><strong>Neural Networks and Deep Learning</strong></p>

<p><a href="http://neuralnetworksanddeeplearning.com">http://neuralnetworksanddeeplearning.com</a></p>

<p><strong>Deep Learning Reading List</strong></p>

<p><a href="http://deeplearning.net/reading-list/">http://deeplearning.net/reading-list/</a></p>

<p><strong>WILDML: A BLOG ABOUT MACHINE LEARNING, DEEP LEARNING AND NLP.</strong></p>

<p><a href="http://www.wildml.com/">http://www.wildml.com/</a></p>

<p><strong>Andrej Karpathy blog</strong></p>

<p><a href="http://karpathy.github.io/">http://karpathy.github.io/</a></p>

<p><strong>Rodrigob’s github page</strong></p>

<p><a href="http://rodrigob.github.io/">http://rodrigob.github.io/</a></p>

<p><strong>colah’s blog</strong></p>

<p><a href="http://colah.github.io/">http://colah.github.io/</a></p>

<p><strong>What My Deep Model Doesn’t Know…</strong></p>

<p><a href="http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html">http://mlg.eng.cam.ac.uk/yarin/blog_3d801aa532c1ce.html</a></p>

<p><strong>Christoph Feichtenhofer</strong></p>

<ul>
  <li>intro: PhD Student, Graz University of Technology</li>
  <li>homepage: <a href="http://feichtenhofer.github.io/">http://feichtenhofer.github.io/</a></li>
</ul>

<p><strong>Image recognition is not enough: As with language, photos need contextual intelligence</strong></p>

<p><a href="https://medium.com/@ken_getquik/image-recognition-is-not-enough-293cd7d58004#.dex817l2z">https://medium.com/@ken_getquik/image-recognition-is-not-enough-293cd7d58004#.dex817l2z</a></p>

<p><strong>ResNets, HighwayNets, and DenseNets, Oh My!</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/@awjuliani/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.pgltg8pro">https://medium.com/@awjuliani/resnets-highwaynets-and-densenets-oh-my-9bb15918ee32#.pgltg8pro</a></li>
  <li>github: <a href="https://github.com/awjuliani/TF-Tutorials/blob/master/Deep%20Network%20Comparison.ipynb">https://github.com/awjuliani/TF-Tutorials/blob/master/Deep%20Network%20Comparison.ipynb</a></li>
</ul>

<p><strong>The Frontiers of Memory and Attention in Deep Learning</strong></p>

<ul>
  <li>sldies: <a href="http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/">http://slides.com/smerity/quora-frontiers-of-memory-and-attention#/</a></li>
</ul>

<p><strong>Design Patterns for Deep Learning Architectures</strong></p>

<p><a href="http://www.deeplearningpatterns.com/doku.php">http://www.deeplearningpatterns.com/doku.php</a></p>

<p><strong>Building a Deep Learning Powered GIF Search Engine</strong></p>

<ul>
  <li>blog: <a href="https://medium.com/@zan2434/building-a-deep-learning-powered-gif-search-engine-a3eb309d7525">https://medium.com/@zan2434/building-a-deep-learning-powered-gif-search-engine-a3eb309d7525</a></li>
</ul>

<p><strong>850k Images in 24 hours: Automating Deep Learning Dataset Creation</strong></p>

<p><a href="https://gab41.lab41.org/850k-images-in-24-hours-automating-deep-learning-dataset-creation-60bdced04275#.xhq9feuxx">https://gab41.lab41.org/850k-images-in-24-hours-automating-deep-learning-dataset-creation-60bdced04275#.xhq9feuxx</a></p>

<p><strong>How six lines of code + SQL Server can bring Deep Learning to ANY App</strong></p>

<ul>
  <li>blog: <a href="https://blogs.technet.microsoft.com/dataplatforminsider/2017/01/05/how-six-lines-of-code-sql-server-can-bring-deep-learning-to-any-app/">https://blogs.technet.microsoft.com/dataplatforminsider/2017/01/05/how-six-lines-of-code-sql-server-can-bring-deep-learning-to-any-app/</a></li>
  <li>github: <a href="https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/Galaxies">https://github.com/Microsoft/SQL-Server-R-Services-Samples/tree/master/Galaxies</a></li>
</ul>

<p><strong>Neural Network Architectures</strong></p>

<p><img src="https://culurciello.github.io/assets/nets/acc_vs_net_vs_ops.svg" height="300" alt="" /></p>

<ul>
  <li>blog: <a href="https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba#.m8y39oih6">https://medium.com/towards-data-science/neural-network-architectures-156e5bad51ba#.m8y39oih6</a></li>
  <li>blog: <a href="https://culurciello.github.io/tech/2016/06/04/nets.html">https://culurciello.github.io/tech/2016/06/04/nets.html</a></li>
</ul>

</body></html>
